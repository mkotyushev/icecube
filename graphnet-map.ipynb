{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Training DynEdge\n","\n","Now that both database and selection is ready, everything is in place to begin training. DynEdge is a GNN implemented in GraphNeT - it represents IceCube events as 3D point clouds and leverages techniques from segmentation analysis in computer vision to reconstruct events. You can find technical details on the model in [this paper](https://iopscience.iop.org/article/10.1088/1748-0221/17/11/P11003). The model and training configuration shown below is nearly identical to what's presented in the paper. Note that this configuration was originally meant for low energy, so it's possible that some adjustments might improve performance."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-02-03T08:35:50.269123Z","iopub.status.busy":"2023-02-03T08:35:50.268509Z","iopub.status.idle":"2023-02-03T08:35:51.121812Z","shell.execute_reply":"2023-02-03T08:35:51.120342Z","shell.execute_reply.started":"2023-02-03T08:35:50.269085Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:38 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230304-185438.log\u001b[0m\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[33mWARNING \u001b[0m 2023-03-04 18:54:39 - warn_once - `icecube` not available. Some functionality may be missing.\u001b[0m\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from collections import defaultdict\n","from copy import deepcopy\n","from graphnet.data.constants import FEATURES, TRUTH\n","from icecube_utils import make_dataloader\n","\n","from icecube_utils import (\n","    load_pretrained_model,\n","    inference, \n","    train_dynedge_from_scratch,\n","    get_acts_wassersteinized_layers_modularized,\n","    compute_activations_across_models_v1,\n","    make_dataloader\n",")\n","from graphnet.training.labels import Direction\n","from parameters import get_parser\n","from train_large import config\n","\n","features = FEATURES.KAGGLE\n","truth = TRUTH.KAGGLE"]},{"cell_type":"markdown","metadata":{},"source":["In the cell below, you can choose between training dynedge from scratch on the batch_1 database or loading in a pretrained model that has trained on batches 1 to 50."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["models = {}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["config_small = deepcopy(config)\n","config_small['dynedge']['dynedge_layer_sizes'] = [(128, 256), (336, 256), (336, 256), (336, 256)]\n","\n","models['small_seed_0_epochs_10'] = load_pretrained_model(config=config_small, state_dict_path='/workspace/icecube/weights/dynedge_pretrained_small_0/state_dict.pth')\n","models['small_seed_1_epochs_10'] = load_pretrained_model(config=config_small, state_dict_path='/workspace/icecube/weights/dynedge_pretrained_small_1/state_dict.pth')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["config_large = deepcopy(config)\n","config_large['dynedge']['dynedge_layer_sizes'] = [(128 * 2, 256 * 2), (336 * 2, 256 * 2), (336 * 2, 256 * 2), (336 * 2, 256 * 2)]\n","\n","models['large_seed_0_epochs_10'] = load_pretrained_model(config=config_large, state_dict_path='/workspace/icecube/weights/dynedge_pretrained_large_0_epochs_10/state_dict.pth')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["config_large = deepcopy(config)\n","config_large['dynedge']['dynedge_layer_sizes'] = [(128 * 2, 256 * 2), (336 * 2, 256 * 2), (336 * 2, 256 * 2), (336 * 2, 256 * 2)]\n","\n","models['large_seed_0_epochs_1'] = load_pretrained_model(config=config_large, state_dict_path='/workspace/icecube/weights/dynedge_pretrained_large_0_epochs_1/state_dict.pth')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# %%capture --no-stdout\n","# config_large_random = deepcopy(config_large)\n","# config_large_random['fit']['max_steps'] = 0\n","# model_large_random = train_dynedge_from_scratch(config=config_large_random)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["parser = get_parser()\n","args = parser.parse_args('--gpu-id 1 --model-name mlpnet --n-epochs 10 --save-result-file sample.csv \\\n","--sweep-name exp_sample --exact --correction --ground-metric euclidean --weight-stats \\\n","--activation-histograms --activation-mode raw --geom-ensemble-type acts --sweep-id 21 \\\n","--act-num-samples 200 --ground-metric-normalize none --activation-seed 21 \\\n","--prelu-acts --recheck-acc --load-models ./mnist_models --ckpt-type final \\\n","--past-correction --not-squared --dist-normalize --print-distances --to-download'.split())\n","\n","args.gpu_id = 0\n","args.proper_marginals = True\n","args.skip_last_layer = True\n","args.skip_personal_idx = False\n","args.act_num_samples = 20\n","args.width_ratio = 1\n","args.dataset = 'icecube'"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_dataloader = make_dataloader(db = config_small['path'],\n","    selection = None, # Entire database\n","    pulsemaps = config_small['pulsemap'],\n","    features = features,\n","    truth = truth,\n","    batch_size = args.act_num_samples,\n","    num_workers = config_small['num_workers'],\n","    shuffle = False,\n","    labels = {'direction': Direction()},\n","    index_column = config_small['index_column'],\n","    truth_table = config_small['truth_table'],\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["layer_names = {\n","    '_gnn._conv_layers.0.nn.0',\n","    '_gnn._conv_layers.0.nn.2',\n","    '_gnn._conv_layers.1.nn.0',\n","    '_gnn._conv_layers.1.nn.2',\n","    '_gnn._conv_layers.2.nn.0',\n","    '_gnn._conv_layers.2.nn.2',\n","    '_gnn._conv_layers.3.nn.0',\n","    '_gnn._conv_layers.3.nn.2',\n","    '_gnn._post_processing.0',\n","    '_gnn._post_processing.2',\n","    '_gnn._readout.0',\n","    '_tasks.0._affine',\n","}\n","\n","def map_model(model_from, model_to, dataloader, n_samples):\n","    models = [\n","        model_from.cuda(),\n","        model_to.cuda(), \n","    ]\n","    with torch.no_grad():\n","        activations = compute_activations_across_models_v1(\n","            args, \n","            models,\n","            dataloader,\n","            n_samples,\n","            mode='raw',\n","            layer_names=layer_names\n","        )\n","        _, mapped_state_dict, _ = get_acts_wassersteinized_layers_modularized(args, models, activations, train_loader=train_dataloader, test_loader=None)\n","        \n","    mapped_state_dict = {\n","        k: v[:, 0] if 'bias' in k else v for k, v in mapped_state_dict.items()\n","    }\n","\n","    model_mapped = deepcopy(model_to)\n","    model_mapped.load_state_dict(mapped_state_dict)\n","\n","    return model_mapped"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n"]},{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [26346], which does not match the required output shape [4391, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [9588], which does not match the required output shape [1598, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [20, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [9102], which does not match the required output shape [1517, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [20, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [20, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [50268], which does not match the required output shape [8378, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [20, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [11196], which does not match the required output shape [1866, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [12240], which does not match the required output shape [2040, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [10620], which does not match the required output shape [1770, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [9516], which does not match the required output shape [1586, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [7488], which does not match the required output shape [1248, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [9666], which does not match the required output shape [1611, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [20, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [9720], which does not match the required output shape [1620, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [107964], which does not match the required output shape [17994, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [20, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [8928], which does not match the required output shape [1488, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:45 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [8118], which does not match the required output shape [1353, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n"]},{"name":"stdout","output_type":"stream","text":["num_personal_idx  0\n","model_name is  mlpnet\n","***********\n","min of act: -1.1325409412384033, max: 1.041191577911377, mean: -0.08256817609071732\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -0.9590854644775391, max: 0.9545162916183472, mean: -0.03809298202395439\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -17.302310943603516, max: 24.802783966064453, mean: -0.6187565326690674\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -23.76776123046875, max: 27.96661949157715, mean: -0.5973536968231201\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -227.50363159179688, max: 169.9368133544922, mean: -3.1012747287750244\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -117.22239685058594, max: 66.76261901855469, mean: -2.4172213077545166\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -76.52189636230469, max: 73.85053253173828, mean: -1.2584871053695679\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -73.33061981201172, max: 23.28693199157715, mean: -1.3345074653625488\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -238.05897521972656, max: 393.1527099609375, mean: -4.286755561828613\n","activations for idx 0 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -225.53237915039062, max: 62.710693359375, mean: -4.75285005569458\n","activations for idx 0 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -76.27462768554688, max: 62.71738052368164, mean: -13.919059753417969\n","activations for idx 0 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -111.15362548828125, max: 2.1177995204925537, mean: -4.961073398590088\n","activations for idx 0 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.3195627927780151, max: 1.1776950359344482, mean: -0.09055199474096298\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -1.3239096403121948, max: 1.0020647048950195, mean: -0.04542992636561394\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -15.780618667602539, max: 14.60289478302002, mean: -0.5592504739761353\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -15.729148864746094, max: 14.771148681640625, mean: -0.6368424296379089\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -74.51190948486328, max: 79.33740234375, mean: -2.2491962909698486\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -56.26295852661133, max: 37.11320495605469, mean: -1.9851322174072266\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -57.66426086425781, max: 63.74408721923828, mean: -1.7765514850616455\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -42.30836486816406, max: 18.80048179626465, mean: -1.558029294013977\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -86.2443618774414, max: 100.25065612792969, mean: -4.028878211975098\n","activations for idx 1 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -77.88961791992188, max: 68.6219482421875, mean: -4.77450704574585\n","activations for idx 1 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -56.87553405761719, max: 48.92001724243164, mean: -10.3360013961792\n","activations for idx 1 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -119.7136459350586, max: 1.4289569854736328, mean: -4.905736446380615\n","activations for idx 1 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","\n","--------------- At layer index 0 ------------- \n"," \n","Previous layer shape is  None\n","In layer _gnn._conv_layers.0.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 67.46237182617188, Mean : 37.161537170410156, Min : 14.58770751953125, Std: 11.582818984985352\n","returns a uniform measure of cardinality:  128\n","returns a uniform measure of cardinality:  128\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12844\n","# of ground metric features in 1 is   12844\n","ground metric (m0) is  tensor([[42.6071, 38.9444, 41.3591,  ..., 47.2328, 38.9551, 37.6503],\n","        [46.3615, 40.6913, 23.9490,  ..., 24.8660, 23.2753, 43.6069],\n","        [82.3012, 74.6541, 46.3220,  ..., 68.2670, 39.5479, 25.8596],\n","        ...,\n","        [39.2099, 28.8007, 29.1562,  ..., 35.2780, 32.7046, 48.3517],\n","        [32.5536, 20.6826, 39.9997,  ..., 34.7269, 46.3815, 66.9922],\n","        [47.4671, 39.2524, 15.8783,  ..., 25.1895, 21.2843, 47.9722]],\n","       device='cuda:0')\n","At layer idx 0 and shape torch.Size([128, 34]), the OT cost is  15.849426910281181\n","shape of T_var is  torch.Size([128, 128])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([128])\n","inverse marginals beta is  tensor([0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0156, device='cuda:0')\n","Here, trace is 1.9999744892120361 and matrix sum is 127.99836730957031 \n","Shape of aligned wt is  torch.Size([128, 34])\n","Shape of fc_layer0_weight_data is  torch.Size([128, 34])\n","\n","--------------- At layer index 1 ------------- \n"," \n","Previous layer shape is  torch.Size([128, 34])\n","In layer _gnn._conv_layers.0.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 50.13129425048828, Mean : 20.511276245117188, Min : 8.245372772216797, Std: 6.975855827331543\n","shape of layer: model 0 torch.Size([256, 128])\n","shape of layer: model 1 torch.Size([256, 128])\n","shape of activations: model 0 torch.Size([256, 12844])\n","shape of activations: model 1 torch.Size([256, 12844])\n","shape of previous transport map torch.Size([128, 128])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12844\n","# of ground metric features in 1 is   12844\n","ground metric (m0) is  tensor([[19.0969, 14.8034, 30.0915,  ..., 18.1531, 18.5941,  9.9147],\n","        [35.5915, 35.0091, 23.4755,  ..., 38.6973, 41.5008, 43.0596],\n","        [18.6155, 19.1411, 23.1098,  ..., 22.1564, 26.0428, 27.5841],\n","        ...,\n","        [17.6380, 17.8006, 45.1490,  ..., 18.1423, 17.6240, 18.1531],\n","        [15.1951, 11.2247, 30.2733,  ..., 15.4081, 15.2438,  9.9626],\n","        [15.6502, 15.3750, 42.8002,  ..., 14.7971, 16.4086, 15.8304]],\n","       device='cuda:0')\n","At layer idx 1 and shape torch.Size([256, 128]), the OT cost is  9.466975797899067\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 128])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 128])\n","\n","--------------- At layer index 2 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 128])\n","In layer _gnn._conv_layers.1.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 376.61883544921875, Mean : 166.41990661621094, Min : 81.57929229736328, Std: 52.23181915283203\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([336, 512])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([336, 12784])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  336\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[197.1263, 129.4896, 108.3517,  ..., 101.4476, 131.5504, 127.2655],\n","        [243.0908, 172.8552, 165.3787,  ..., 156.8919, 188.0816, 179.6191],\n","        [145.3249, 186.9105, 158.1939,  ..., 177.0380, 182.2410, 159.0058],\n","        ...,\n","        [319.9445, 219.8507, 257.2922,  ..., 281.0363, 215.9292, 217.3801],\n","        [177.0410, 154.7195, 126.6046,  ..., 146.4763, 144.8056, 151.7146],\n","        [168.9985, 199.1084, 167.3420,  ..., 187.6619, 183.7834, 169.6169]],\n","       device='cuda:0')\n","At layer idx 2 and shape torch.Size([336, 512]), the OT cost is  96.23397453625995\n","shape of T_var is  torch.Size([336, 336])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([336])\n","inverse marginals beta is  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999664425849915, min 0.0, mean 0.0029760904144495726, std 0.05447164550423622 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 335.98870849609375 \n","Shape of aligned wt is  torch.Size([336, 512])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 3 ------------- \n"," \n","Previous layer shape is  torch.Size([336, 512])\n","In layer _gnn._conv_layers.1.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 381.51959228515625, Mean : 156.9964599609375, Min : 90.04899597167969, Std: 46.17608642578125\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([256, 336])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([256, 12784])\n","shape of previous transport map torch.Size([336, 336])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 87.6034, 114.4559,  80.7563,  ..., 183.6849, 235.8055, 168.8284],\n","        [ 70.9971,  72.6473,  88.6008,  ..., 132.9771, 179.2225, 111.4460],\n","        [252.6307, 229.7185, 271.8376,  ..., 186.6957, 209.5234, 201.4606],\n","        ...,\n","        [ 74.2258, 102.2960,  77.3313,  ..., 140.2413, 213.5050, 146.0388],\n","        [124.1116, 128.6680, 140.1380,  ..., 188.4470, 228.5372, 159.3594],\n","        [106.6945, 124.5537, 100.7833,  ..., 190.4971, 232.6437, 161.8033]],\n","       device='cuda:0')\n","At layer idx 3 and shape torch.Size([256, 336]), the OT cost is  100.90587885677814\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 336])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 4 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 336])\n","In layer _gnn._conv_layers.2.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1699.1142578125, Mean : 715.6792602539062, Min : 463.6197509765625, Std: 200.7945556640625\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([336, 512])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([336, 12784])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  336\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 723.1049,  752.5516,  719.3176,  ...,  614.6531,  733.4761,\n","          778.5185],\n","        [1021.9734, 1164.8236, 1122.3436,  ...,  907.5428,  981.2109,\n","          976.5396],\n","        [ 401.7274,  437.4203,  472.6629,  ...,  433.9647,  633.8701,\n","          800.4945],\n","        ...,\n","        [ 581.0363,  666.5806,  768.8175,  ...,  621.4958,  835.6966,\n","          999.7999],\n","        [ 621.5082,  772.8813,  792.0935,  ...,  572.2359,  709.0413,\n","          815.9390],\n","        [ 709.8576,  827.1917,  737.5626,  ...,  519.0978,  607.7025,\n","          655.5925]], device='cuda:0')\n","At layer idx 4 and shape torch.Size([336, 512]), the OT cost is  519.1302176884242\n","shape of T_var is  torch.Size([336, 336])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([336])\n","inverse marginals beta is  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999664425849915, min 0.0, mean 0.00297609088011086, std 0.05447164550423622 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 335.9887390136719 \n","Shape of aligned wt is  torch.Size([336, 512])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 5 ------------- \n"," \n","Previous layer shape is  torch.Size([336, 512])\n","In layer _gnn._conv_layers.2.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 978.252685546875, Mean : 429.3626403808594, Min : 312.2447814941406, Std: 110.77699279785156\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([256, 336])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([256, 12784])\n","shape of previous transport map torch.Size([336, 336])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[532.0198, 454.9887, 454.5200,  ..., 381.1374, 560.0784, 437.2970],\n","        [351.1339, 655.0722, 467.5754,  ..., 464.8448, 804.0782, 583.8842],\n","        [661.5720, 445.9702, 544.8301,  ..., 453.6554, 513.5737, 463.2307],\n","        ...,\n","        [482.7851, 365.7108, 361.4013,  ..., 280.1620, 468.6232, 329.2673],\n","        [303.0605, 602.0454, 388.2560,  ..., 400.3981, 747.0553, 514.1981],\n","        [352.4853, 407.6601, 200.6733,  ..., 221.4366, 506.4879, 276.1996]],\n","       device='cuda:0')\n","At layer idx 5 and shape torch.Size([256, 336]), the OT cost is  340.48864990472794\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0039, device='cuda:0')\n","Here, trace is 0.9999743700027466 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 336])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 6 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 336])\n","In layer _gnn._conv_layers.3.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1375.3839111328125, Mean : 581.9491577148438, Min : 345.17132568359375, Std: 190.4644317626953\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([336, 512])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([336, 12784])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  336\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 357.7878,  580.1754,  810.2770,  ...,  404.4682,  752.3852,\n","          271.7469],\n","        [ 356.8770,  594.8699,  781.5636,  ...,  403.3100,  739.3098,\n","          289.2249],\n","        [ 833.3171,  798.8217, 1165.0996,  ...,  857.6437, 1138.5244,\n","          743.5383],\n","        ...,\n","        [ 354.6942,  542.7382,  806.5966,  ...,  399.3716,  756.8184,\n","          246.5269],\n","        [ 613.9951,  517.1731, 1053.4991,  ...,  654.2063, 1009.4427,\n","          466.5718],\n","        [ 408.6026,  877.3458,  597.3290,  ...,  403.6711,  559.1515,\n","          504.9410]], device='cuda:0')\n","At layer idx 6 and shape torch.Size([336, 512]), the OT cost is  431.5210777464366\n","shape of T_var is  torch.Size([336, 336])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([336])\n","inverse marginals beta is  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999664425849915, min 0.0, mean 0.00297609088011086, std 0.05447164550423622 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 335.9887390136719 \n","Shape of aligned wt is  torch.Size([336, 512])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 7 ------------- \n"," \n","Previous layer shape is  torch.Size([336, 512])\n","In layer _gnn._conv_layers.3.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 815.013916015625, Mean : 268.3914794921875, Min : 193.928466796875, Std: 74.74432373046875\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([256, 336])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([256, 12784])\n","shape of previous transport map torch.Size([336, 336])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[246.1184, 243.7467, 263.4279,  ..., 454.8751, 240.1961, 352.9356],\n","        [186.0359, 149.2616, 273.1942,  ..., 519.4965, 210.5548, 207.3027],\n","        [218.6550, 213.5928, 255.2827,  ..., 464.7334, 219.7222, 314.2408],\n","        ...,\n","        [315.0682, 326.5807, 284.4296,  ..., 419.6090, 292.7748, 454.4953],\n","        [133.5428, 129.0961, 208.8896,  ..., 456.0411, 151.5844, 237.5382],\n","        [184.4321, 185.1462, 234.2523,  ..., 457.3962, 193.3033, 286.6789]],\n","       device='cuda:0')\n","At layer idx 7 and shape torch.Size([256, 336]), the OT cost is  221.9524082839489\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 336])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 8 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 336])\n","In layer _gnn._post_processing.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1285.0343017578125, Mean : 396.6560363769531, Min : 211.80995178222656, Std: 161.8671112060547\n","shape of layer: model 0 torch.Size([336, 1041])\n","shape of layer: model 1 torch.Size([336, 1041])\n","shape of activations: model 0 torch.Size([336, 1598])\n","shape of activations: model 1 torch.Size([336, 1598])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([336, 1041])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  336\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   1598\n","# of ground metric features in 1 is   1598\n","ground metric (m0) is  tensor([[575.1707,  88.2823, 407.9821,  ..., 430.8534, 114.1656, 113.3528],\n","        [559.2667, 112.8185, 383.0252,  ..., 413.9481, 120.8655, 130.5112],\n","        [545.1895, 103.5940, 377.7263,  ..., 400.6024,  95.5273,  97.2590],\n","        ...,\n","        [532.8197, 694.1583, 480.2880,  ..., 497.9479, 651.2030, 641.6056],\n","        [609.3253, 546.2787, 446.9779,  ..., 461.8874, 536.3365, 500.4799],\n","        [487.8568, 491.5362, 456.1027,  ..., 465.6777, 445.2830, 450.5088]],\n","       device='cuda:0')\n","At layer idx 8 and shape torch.Size([336, 1041]), the OT cost is  240.00478062175566\n","shape of T_var is  torch.Size([336, 336])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([336])\n","inverse marginals beta is  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999664425849915, min 0.0, mean 0.0029760904144495726, std 0.05447164550423622 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0060, device='cuda:0')\n","Here, trace is 1.999932885169983 and matrix sum is 335.98870849609375 \n","Shape of aligned wt is  torch.Size([336, 1041])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 1041])\n","\n","--------------- At layer index 9 ------------- \n"," \n","Previous layer shape is  torch.Size([336, 1041])\n","In layer _gnn._post_processing.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 705.2745361328125, Mean : 368.5431213378906, Min : 214.9173583984375, Std: 103.21635437011719\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([256, 336])\n","shape of activations: model 0 torch.Size([256, 1598])\n","shape of activations: model 1 torch.Size([256, 1598])\n","shape of previous transport map torch.Size([336, 336])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   1598\n","# of ground metric features in 1 is   1598\n","ground metric (m0) is  tensor([[418.1498, 375.4735, 276.5624,  ..., 580.3307, 347.1684, 277.1048],\n","        [428.0421, 493.6685, 443.0647,  ..., 582.1590, 509.2257, 457.4919],\n","        [489.1674, 462.8477, 243.5589,  ..., 589.8008, 310.7854, 250.9262],\n","        ...,\n","        [454.2281, 403.5679, 287.7692,  ..., 677.8340, 404.2147, 284.1656],\n","        [559.9719, 465.0182, 163.9564,  ..., 742.1949, 296.2231, 136.5109],\n","        [600.9287, 603.4753, 248.5619,  ..., 771.6055, 399.0973, 258.7022]],\n","       device='cuda:0')\n","At layer idx 9 and shape torch.Size([256, 336]), the OT cost is  227.76537157595158\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0117, device='cuda:0')\n","Here, trace is 2.9999232292175293 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 336])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 10 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 336])\n","In layer _gnn._readout.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 118.78968811035156, Mean : 69.14907836914062, Min : 27.821407318115234, Std: 22.849210739135742\n","shape of layer: model 0 torch.Size([128, 768])\n","shape of layer: model 1 torch.Size([128, 768])\n","shape of activations: model 0 torch.Size([128, 20])\n","shape of activations: model 1 torch.Size([128, 20])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([128, 768])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  128\n","returns a uniform measure of cardinality:  128\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   20\n","# of ground metric features in 1 is   20\n","ground metric (m0) is  tensor([[ 72.0315,  27.0874,  83.4255,  ...,  28.0288,  22.3925,  84.4473],\n","        [ 70.2021,  58.3579,  89.0331,  ...,  75.6756,  62.4265,  89.8887],\n","        [108.7049, 112.9185,  53.7416,  ..., 125.5712, 116.9021,  89.3214],\n","        ...,\n","        [ 88.5096,  36.9272,  89.3748,  ...,  24.5146,  18.8485,  99.8203],\n","        [ 94.6544,  98.7892,  67.3121,  ..., 115.4740, 102.6246,  92.1988],\n","        [ 80.3593,  29.7452,  87.9190,  ...,  20.7850,  16.2932,  93.4210]],\n","       device='cuda:0')\n","At layer idx 10 and shape torch.Size([128, 768]), the OT cost is  34.47275027632713\n","shape of T_var is  torch.Size([128, 128])\n","T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([128])\n","inverse marginals beta is  tensor([0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0156, device='cuda:0')\n","Here, trace is 1.9999744892120361 and matrix sum is 127.99836730957031 \n","Shape of aligned wt is  torch.Size([128, 768])\n","Shape of fc_layer0_weight_data is  torch.Size([128, 768])\n","\n","--------------- At layer index 11 ------------- \n"," \n","Previous layer shape is  torch.Size([128, 768])\n","In layer _tasks.0._affine.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 113.61737060546875, Mean : 58.521026611328125, Min : 14.627141952514648, Std: 52.28050231933594\n","shape of layer: model 0 torch.Size([3, 128])\n","shape of layer: model 1 torch.Size([3, 128])\n","shape of activations: model 0 torch.Size([3, 20])\n","shape of activations: model 1 torch.Size([3, 20])\n","shape of previous transport map torch.Size([128, 128])\n","returns a uniform measure of cardinality:  3\n","returns a uniform measure of cardinality:  3\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   20\n","# of ground metric features in 1 is   20\n","Simple averaging of last layer weights. NO transport map needs to be computed\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:47 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","num_personal_idx  0\n","model_name is  mlpnet\n","***********\n","min of act: -1.1325409412384033, max: 1.041191577911377, mean: -0.08256817609071732\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -0.9590854644775391, max: 0.9545162916183472, mean: -0.03809298574924469\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -17.302310943603516, max: 24.802783966064453, mean: -0.6187565326690674\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -23.767759323120117, max: 27.966615676879883, mean: -0.5973536968231201\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -227.50363159179688, max: 169.9368133544922, mean: -3.1012747287750244\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -117.22239685058594, max: 66.76261901855469, mean: -2.4172213077545166\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -76.52191162109375, max: 73.85054016113281, mean: -1.2584871053695679\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -73.33061218261719, max: 23.286935806274414, mean: -1.3345074653625488\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -238.05897521972656, max: 393.1526794433594, mean: -4.286755561828613\n","activations for idx 0 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -225.53236389160156, max: 62.71070861816406, mean: -4.75285005569458\n","activations for idx 0 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -76.27462768554688, max: 62.71738052368164, mean: -13.919058799743652\n","activations for idx 0 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -111.15361022949219, max: 2.1177995204925537, mean: -4.961073875427246\n","activations for idx 0 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.1998363733291626, max: 1.0438960790634155, mean: -0.08504427969455719\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -1.461012601852417, max: 1.2009639739990234, mean: -0.06599871814250946\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 512])\n","-----------\n","***********\n","min of act: -15.009547233581543, max: 10.419257164001465, mean: -0.6172375679016113\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -12.513638496398926, max: 15.264681816101074, mean: -0.5694918632507324\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -98.17100524902344, max: 91.93549346923828, mean: -2.6535470485687256\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -80.1131362915039, max: 51.153472900390625, mean: -2.355632781982422\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -56.18081283569336, max: 73.34707641601562, mean: -1.2438921928405762\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -65.31316375732422, max: 45.30332946777344, mean: -1.8433563709259033\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -138.939453125, max: 185.67538452148438, mean: -6.390253067016602\n","activations for idx 1 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -107.00572967529297, max: 57.30133819580078, mean: -4.761904239654541\n","activations for idx 1 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -72.4833755493164, max: 55.33736801147461, mean: -10.512134552001953\n","activations for idx 1 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -102.25068664550781, max: 0.9168318510055542, mean: -5.262628078460693\n","activations for idx 1 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","\n","--------------- At layer index 0 ------------- \n"," \n","Previous layer shape is  None\n","In layer _gnn._conv_layers.0.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 69.66048431396484, Mean : 36.43328094482422, Min : 13.651773452758789, Std: 11.08304214477539\n","returns a uniform measure of cardinality:  128\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12844\n","# of ground metric features in 1 is   12844\n","ground metric (m0) is  tensor([[32.5203, 42.3346, 45.0413,  ..., 36.8220, 30.8624, 35.5469],\n","        [36.2338, 38.0593, 33.1562,  ..., 16.6512, 36.0133, 10.3754],\n","        [66.3676, 76.4970, 69.1982,  ..., 52.9281, 67.5613, 56.4832],\n","        ...,\n","        [28.9836, 31.3000, 30.9940,  ..., 28.1580, 28.4525, 25.0592],\n","        [26.9602, 21.6103, 23.1439,  ..., 38.9729, 27.4273, 32.6819],\n","        [37.0747, 36.0544, 28.9612,  ..., 19.3956, 36.8397, 18.9995]],\n","       device='cuda:0')\n","At layer idx 0 and shape torch.Size([256, 34]), the OT cost is  15.54270999506116\n","shape of T_var is  torch.Size([128, 256])\n","T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.007812299765646458, std 0.08804149180650711 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([128, 34])\n","Shape of fc_layer0_weight_data is  torch.Size([128, 34])\n","\n","--------------- At layer index 1 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 34])\n","In layer _gnn._conv_layers.0.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 61.30876159667969, Mean : 20.490821838378906, Min : 8.106955528259277, Std: 7.238737106323242\n","shape of layer: model 0 torch.Size([256, 128])\n","shape of layer: model 1 torch.Size([512, 256])\n","shape of activations: model 0 torch.Size([256, 12844])\n","shape of activations: model 1 torch.Size([512, 12844])\n","shape of previous transport map torch.Size([128, 256])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12844\n","# of ground metric features in 1 is   12844\n","ground metric (m0) is  tensor([[16.0224, 33.5804, 23.6899,  ..., 22.0026, 35.8173, 10.0349],\n","        [30.6258, 50.3703, 56.3788,  ..., 27.6910, 64.7147, 34.5402],\n","        [14.1375, 41.9426, 42.3748,  ..., 18.2958, 47.0482, 17.6285],\n","        ...,\n","        [19.4908, 44.3715, 31.7493,  ..., 31.7743, 18.9571, 18.2210],\n","        [14.1311, 30.9173, 23.1178,  ..., 20.3712, 33.7260, 10.4751],\n","        [18.9364, 37.8232, 27.6924,  ..., 28.7471, 21.9580, 17.7731]],\n","       device='cuda:0')\n","At layer idx 1 and shape torch.Size([512, 256]), the OT cost is  10.365363880526274\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0.0020, device='cuda:0')\n","Here, trace is 0.7070705890655518 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 256])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 128])\n","\n","--------------- At layer index 2 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 256])\n","In layer _gnn._conv_layers.1.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 436.4130859375, Mean : 160.87831115722656, Min : 81.26689147949219, Std: 53.00154113769531\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([672, 1024])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([672, 12784])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  672\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[131.6083, 273.0560, 136.0597,  ..., 156.2898, 128.7064, 207.3693],\n","        [183.6645, 320.3793, 161.4526,  ..., 208.7665, 179.1745, 265.9783],\n","        [176.1943, 289.4075, 213.8707,  ..., 209.8737, 174.0944, 159.5159],\n","        ...,\n","        [207.9724, 150.6470, 255.1024,  ..., 189.3219, 209.3120, 275.5472],\n","        [157.8508, 230.4366, 214.9772,  ..., 160.7185, 157.1372, 208.3661],\n","        [181.4682, 281.6798, 222.6306,  ..., 208.0737, 182.1006, 161.4803]],\n","       device='cuda:0')\n","At layer idx 2 and shape torch.Size([672, 1024]), the OT cost is  95.92571740491049\n","shape of T_var is  torch.Size([336, 672])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([672])\n","inverse marginals beta is  tensor([0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015], device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999328255653381, min 0.0, mean 0.002975990530103445, std 0.05446968972682953 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 475.143798828125 \n","Shape of aligned wt is  torch.Size([336, 1024])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 3 ------------- \n"," \n","Previous layer shape is  torch.Size([672, 1024])\n","In layer _gnn._conv_layers.1.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 467.1571350097656, Mean : 149.3040771484375, Min : 87.25532531738281, Std: 51.72022247314453\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([512, 672])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([512, 12784])\n","shape of previous transport map torch.Size([336, 672])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 98.8722, 109.0456, 253.6192,  ...,  88.2028, 123.0435,  92.4750],\n","        [132.5914,  89.7171, 203.6238,  ...,  68.2052,  71.7752,  68.4876],\n","        [314.1315, 255.4014, 206.3571,  ..., 248.7979, 219.2145, 243.5827],\n","        ...,\n","        [109.2836,  92.4359, 216.8308,  ...,  68.4435,  99.7445,  64.2175],\n","        [156.4780, 153.5070, 242.3000,  ..., 130.4719, 132.1512, 125.5446],\n","        [124.8898, 119.6721, 264.0648,  ..., 105.4455, 131.2625, 116.7125]],\n","       device='cuda:0')\n","At layer idx 3 and shape torch.Size([512, 672]), the OT cost is  96.76595102250576\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 672])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 4 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 672])\n","In layer _gnn._conv_layers.2.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1855.20947265625, Mean : 731.5770874023438, Min : 469.67431640625, Std: 214.47984313964844\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([672, 1024])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([672, 12784])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  672\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 705.5743,  601.5639,  674.6705,  ...,  893.7962,  693.3785,\n","         1352.3025],\n","        [1082.6248,  974.4058,  974.8863,  ..., 1259.1355, 1103.0958,\n","         1723.5767],\n","        [ 381.2328,  323.4471,  427.5292,  ...,  617.4088,  435.3042,\n","         1100.9338],\n","        ...,\n","        [ 655.4409,  667.5375,  693.1566,  ...,  786.5049,  757.8138,\n","         1212.0864],\n","        [ 674.2502,  608.6804,  609.0406,  ...,  913.7524,  721.8440,\n","         1384.0707],\n","        [ 678.0556,  563.5925,  596.8884,  ...,  976.0370,  695.3503,\n","         1470.0787]], device='cuda:0')\n","At layer idx 4 and shape torch.Size([672, 1024]), the OT cost is  533.2626418159122\n","shape of T_var is  torch.Size([336, 672])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([672])\n","inverse marginals beta is  tensor([0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015], device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999328255653381, min 0.0, mean 0.002975990530103445, std 0.05446968972682953 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 475.1438293457031 \n","Shape of aligned wt is  torch.Size([336, 1024])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 5 ------------- \n"," \n","Previous layer shape is  torch.Size([672, 1024])\n","In layer _gnn._conv_layers.2.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1582.440673828125, Mean : 460.511474609375, Min : 325.1044616699219, Std: 154.14996337890625\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([512, 672])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([512, 12784])\n","shape of previous transport map torch.Size([336, 672])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[406.6103, 393.0279, 722.9924,  ..., 429.9730, 400.7380, 420.8324],\n","        [522.9674, 458.5956, 590.3333,  ..., 516.9632, 547.9005, 548.1125],\n","        [468.6277, 477.4089, 845.0172,  ..., 510.1226, 450.5207, 467.0057],\n","        ...,\n","        [315.2588, 297.2505, 677.4079,  ..., 345.3948, 323.9812, 323.0448],\n","        [459.0980, 389.0699, 519.2760,  ..., 438.8463, 494.5414, 484.6075],\n","        [288.4730, 204.6360, 506.3249,  ..., 263.2543, 341.6718, 303.9798]],\n","       device='cuda:0')\n","At layer idx 5 and shape torch.Size([512, 672]), the OT cost is  368.536995023489\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 672])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 6 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 672])\n","In layer _gnn._conv_layers.3.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1601.625732421875, Mean : 589.1632080078125, Min : 342.2699890136719, Std: 194.1444091796875\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([672, 1024])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([672, 12784])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  672\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 587.2789, 1523.0723,  366.7694,  ...,  365.2168,  823.9538,\n","          455.6613],\n","        [ 556.0453, 1560.6682,  338.2776,  ...,  370.1215,  871.1494,\n","          423.8245],\n","        [1005.0195, 1435.5322,  739.6777,  ...,  765.9443,  888.2578,\n","          860.6536],\n","        ...,\n","        [ 548.7424, 1536.4491,  275.5571,  ...,  345.6620,  849.3381,\n","          402.1440],\n","        [ 845.1379, 1288.1105,  488.6259,  ...,  504.4221,  637.3065,\n","          661.7130],\n","        [ 488.1563, 1854.2672,  569.9268,  ...,  562.5813, 1168.0872,\n","          500.0393]], device='cuda:0')\n","At layer idx 6 and shape torch.Size([672, 1024]), the OT cost is  445.2935807364327\n","shape of T_var is  torch.Size([336, 672])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([672])\n","inverse marginals beta is  tensor([0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015], device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999328255653381, min 0.0, mean 0.0029759907629340887, std 0.05446968972682953 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0.0015, device='cuda:0')\n","Here, trace is 0.7070592641830444 and matrix sum is 475.1438293457031 \n","Shape of aligned wt is  torch.Size([336, 1024])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 7 ------------- \n"," \n","Previous layer shape is  torch.Size([672, 1024])\n","In layer _gnn._conv_layers.3.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1013.829345703125, Mean : 292.984619140625, Min : 186.91943359375, Std: 111.95081329345703\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([512, 672])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([512, 12784])\n","shape of previous transport map torch.Size([336, 672])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[243.9304, 240.4638, 226.3442,  ..., 395.6093, 252.3707, 269.2119],\n","        [208.5473, 152.0273, 194.6533,  ..., 459.8462, 131.7874, 161.8904],\n","        [217.7472, 207.5792, 205.7360,  ..., 402.6706, 217.2465, 235.5954],\n","        ...,\n","        [297.1331, 320.3611, 279.1500,  ..., 361.3873, 342.9123, 353.3944],\n","        [166.5979, 124.0555, 153.2101,  ..., 413.4089, 131.4572, 155.3333],\n","        [197.9239, 173.0271, 188.0715,  ..., 405.2745, 187.6169, 208.4708]],\n","       device='cuda:0')\n","At layer idx 7 and shape torch.Size([512, 672]), the OT cost is  242.42661261558533\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0.0039, device='cuda:0')\n","Here, trace is 1.4141411781311035 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 672])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 8 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 672])\n","In layer _gnn._post_processing.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 1841.38037109375, Mean : 474.7901916503906, Min : 229.0026092529297, Std: 266.1507568359375\n","shape of layer: model 0 torch.Size([336, 1041])\n","shape of layer: model 1 torch.Size([336, 2065])\n","shape of activations: model 0 torch.Size([336, 1598])\n","shape of activations: model 1 torch.Size([336, 1598])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 1041])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  336\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   1598\n","# of ground metric features in 1 is   1598\n","ground metric (m0) is  tensor([[ 87.1848, 201.8485, 634.3749,  ..., 829.4681, 776.1733, 184.0215],\n","        [123.1719, 184.4132, 609.5157,  ..., 791.4921, 751.5358, 163.2126],\n","        [100.1298, 180.5452, 598.9049,  ..., 801.8337, 748.2072, 164.8262],\n","        ...,\n","        [698.1287, 581.9205, 598.0560,  ..., 642.8651, 620.5360, 639.5616],\n","        [544.0016, 503.9019, 627.4914,  ..., 712.8641, 700.0153, 538.4399],\n","        [495.0496, 431.8399, 574.4518,  ..., 766.3391, 733.2729, 446.5090]],\n","       device='cuda:0')\n","At layer idx 8 and shape torch.Size([336, 2065]), the OT cost is  314.944252649943\n","shape of T_var is  torch.Size([336, 336])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([336])\n","inverse marginals beta is  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999664425849915, min 0.0, mean 0.00297609088011086, std 0.05447164550423622 \n","scale is  0.7100114243871647\n","Ratio of trace to the matrix sum:  tensor(0.0030, device='cuda:0')\n","Here, trace is 0.7099875807762146 and matrix sum is 238.55581665039062 \n","Shape of aligned wt is  torch.Size([336, 2065])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 1041])\n","\n","--------------- At layer index 9 ------------- \n"," \n","Previous layer shape is  torch.Size([336, 2065])\n","In layer _gnn._post_processing.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 842.5364379882812, Mean : 393.5716552734375, Min : 227.8778076171875, Std: 119.33447265625\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([256, 336])\n","shape of activations: model 0 torch.Size([256, 1598])\n","shape of activations: model 1 torch.Size([256, 1598])\n","shape of previous transport map torch.Size([336, 336])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   1598\n","# of ground metric features in 1 is   1598\n","ground metric (m0) is  tensor([[436.8454, 378.4460, 305.0444,  ..., 309.0615, 375.5231, 314.7483],\n","        [512.7188, 478.5736, 488.2360,  ..., 448.6382, 506.3293, 415.2643],\n","        [518.5625, 442.6077, 319.0205,  ..., 264.3845, 308.7932, 302.9483],\n","        ...,\n","        [436.4492, 402.0262, 348.1126,  ..., 306.7455, 405.7825, 393.8742],\n","        [559.1271, 498.7997, 332.9985,  ..., 183.7740, 285.6868, 391.2654],\n","        [640.4890, 596.6998, 473.9160,  ..., 220.2294, 292.2575, 460.1659]],\n","       device='cuda:0')\n","At layer idx 9 and shape torch.Size([256, 336]), the OT cost is  247.1366734057665\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 336])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 10 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 336])\n","In layer _gnn._readout.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 126.4847640991211, Mean : 68.21671295166016, Min : 25.033309936523438, Std: 25.322399139404297\n","shape of layer: model 0 torch.Size([128, 768])\n","shape of layer: model 1 torch.Size([128, 768])\n","shape of activations: model 0 torch.Size([128, 20])\n","shape of activations: model 1 torch.Size([128, 20])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([128, 768])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  128\n","returns a uniform measure of cardinality:  128\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   20\n","# of ground metric features in 1 is   20\n","ground metric (m0) is  tensor([[ 45.1118,  22.9644,  28.7996,  ...,  29.5138,  66.4333,  29.1337],\n","        [ 62.7644,  42.9890,  61.4853,  ...,  52.5302,  65.2851,  45.3116],\n","        [ 70.5019,  92.3781, 126.9648,  ..., 102.3121,  77.7528, 105.7837],\n","        ...,\n","        [ 56.3775,  40.4611,  38.1742,  ...,  42.6995,  82.6457,  45.1092],\n","        [ 68.4478,  76.0536, 109.2821,  ...,  87.1752,  69.1088,  86.5587],\n","        [ 53.0213,  32.5282,  29.8477,  ...,  36.7522,  76.2270,  37.1952]],\n","       device='cuda:0')\n","At layer idx 10 and shape torch.Size([128, 768]), the OT cost is  32.585707634687424\n","shape of T_var is  torch.Size([128, 128])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([128])\n","inverse marginals beta is  tensor([0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0078, device='cuda:0')\n","Here, trace is 0.9999872446060181 and matrix sum is 127.99836730957031 \n","Shape of aligned wt is  torch.Size([128, 768])\n","Shape of fc_layer0_weight_data is  torch.Size([128, 768])\n","\n","--------------- At layer index 11 ------------- \n"," \n","Previous layer shape is  torch.Size([128, 768])\n","In layer _tasks.0._affine.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 102.8113021850586, Mean : 57.46178436279297, Min : 12.289182662963867, Std: 47.452606201171875\n","shape of layer: model 0 torch.Size([3, 128])\n","shape of layer: model 1 torch.Size([3, 128])\n","shape of activations: model 0 torch.Size([3, 20])\n","shape of activations: model 1 torch.Size([3, 20])\n","shape of previous transport map torch.Size([128, 128])\n","returns a uniform measure of cardinality:  3\n","returns a uniform measure of cardinality:  3\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   20\n","# of ground metric features in 1 is   20\n","Simple averaging of last layer weights. NO transport map needs to be computed\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:51 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","num_personal_idx  0\n","model_name is  mlpnet\n","***********\n","min of act: -1.1325409412384033, max: 1.041191577911377, mean: -0.08256817609071732\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -0.9590854644775391, max: 0.9545163512229919, mean: -0.03809298574924469\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -17.302310943603516, max: 24.802783966064453, mean: -0.6187565326690674\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -23.767759323120117, max: 27.966617584228516, mean: -0.5973536968231201\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -227.50364685058594, max: 169.9368133544922, mean: -3.1012747287750244\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -117.22240447998047, max: 66.76261138916016, mean: -2.4172213077545166\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -76.52191162109375, max: 73.85054016113281, mean: -1.2584871053695679\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -73.33061981201172, max: 23.28693199157715, mean: -1.3345074653625488\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -238.05897521972656, max: 393.1527404785156, mean: -4.286755561828613\n","activations for idx 0 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -225.53237915039062, max: 62.710697174072266, mean: -4.75285005569458\n","activations for idx 0 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -76.27462768554688, max: 62.717384338378906, mean: -13.919058799743652\n","activations for idx 0 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -111.15361022949219, max: 2.1177978515625, mean: -4.961073875427246\n","activations for idx 0 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.206117033958435, max: 1.1342575550079346, mean: 0.011200600303709507\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -0.6341204047203064, max: 0.40778422355651855, mean: -0.025084378197789192\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 512])\n","-----------\n","***********\n","min of act: -1.0388871431350708, max: 1.0029711723327637, mean: -0.046081025153398514\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -0.3677891790866852, max: 0.3867277503013611, mean: -0.019299069419503212\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -0.7410973906517029, max: 0.9487234354019165, mean: -0.015333070419728756\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -0.3182658553123474, max: 0.4013306796550751, mean: -0.008753877133131027\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -0.8714078664779663, max: 0.9499642848968506, mean: -0.00609301682561636\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -0.3247082829475403, max: 0.30105137825012207, mean: -0.004515121690928936\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -0.9056965112686157, max: 1.9894651174545288, mean: -0.14758174121379852\n","activations for idx 1 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -0.5171955823898315, max: 0.6803629994392395, mean: -0.01588740572333336\n","activations for idx 1 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -0.15720397233963013, max: 0.21900266408920288, mean: -0.008149251341819763\n","activations for idx 1 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -0.02662111259996891, max: 0.15974685549736023, mean: 0.024135129526257515\n","activations for idx 1 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","\n","--------------- At layer index 0 ------------- \n"," \n","Previous layer shape is  None\n","In layer _gnn._conv_layers.0.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 82.20773315429688, Mean : 39.64473342895508, Min : 15.516215324401855, Std: 13.885522842407227\n","returns a uniform measure of cardinality:  128\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12844\n","# of ground metric features in 1 is   12844\n","ground metric (m0) is  tensor([[24.9771, 34.2632, 43.6485,  ..., 34.5541, 20.5159, 39.8337],\n","        [26.4112, 26.5227, 24.1722,  ..., 25.1141, 27.4684, 29.8173],\n","        [56.2904, 61.0116, 43.9784,  ..., 36.8803, 50.0990, 28.8394],\n","        ...,\n","        [22.7619, 17.9024, 28.9493,  ..., 33.0070, 24.1090, 38.4884],\n","        [28.5288, 21.1862, 39.6072,  ..., 50.2466, 34.8715, 56.3980],\n","        [27.3936, 22.3013, 17.1130,  ..., 26.5445, 31.1008, 31.8418]],\n","       device='cuda:0')\n","At layer idx 0 and shape torch.Size([256, 34]), the OT cost is  20.414297506213188\n","shape of T_var is  torch.Size([128, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.007812299765646458, std 0.08804149180650711 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0039, device='cuda:0')\n","Here, trace is 0.9999743700027466 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([128, 34])\n","Shape of fc_layer0_weight_data is  torch.Size([128, 34])\n","\n","--------------- At layer index 1 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 34])\n","In layer _gnn._conv_layers.0.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 36.25541687011719, Mean : 18.045398712158203, Min : 9.559813499450684, Std: 4.689885139465332\n","shape of layer: model 0 torch.Size([256, 128])\n","shape of layer: model 1 torch.Size([512, 256])\n","shape of activations: model 0 torch.Size([256, 12844])\n","shape of activations: model 1 torch.Size([512, 12844])\n","shape of previous transport map torch.Size([128, 256])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12844\n","# of ground metric features in 1 is   12844\n","ground metric (m0) is  tensor([[12.6687, 13.1774, 10.6283,  ..., 20.4075, 12.0466, 16.7259],\n","        [35.1910, 31.5334, 31.2306,  ..., 24.9349, 33.3246, 44.2991],\n","        [18.7959, 21.5267, 17.4930,  ..., 20.7586, 21.4615, 26.1002],\n","        ...,\n","        [16.7575, 27.1146, 23.9566,  ..., 35.6166, 25.0389, 10.8766],\n","        [ 9.8754, 13.2478,  9.8757,  ..., 21.2519, 12.0874, 14.6496],\n","        [14.8469, 24.9974, 21.9219,  ..., 34.3254, 23.3220,  9.8867]],\n","       device='cuda:0')\n","At layer idx 1 and shape torch.Size([512, 256]), the OT cost is  11.085845455992967\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0.0059, device='cuda:0')\n","Here, trace is 2.1212117671966553 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 256])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 128])\n","\n","--------------- At layer index 2 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 256])\n","In layer _gnn._conv_layers.1.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 166.76272583007812, Mean : 135.09268188476562, Min : 111.6278076171875, Std: 9.118520736694336\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([672, 1024])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([672, 12784])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  672\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[172.0155, 172.7441, 181.3223,  ..., 202.2605, 193.8951, 188.1249],\n","        [220.2715, 220.0548, 223.4880,  ..., 240.2135, 234.2749, 231.5222],\n","        [194.2975, 195.0035, 201.5483,  ..., 215.7521, 208.9581, 209.1423],\n","        ...,\n","        [171.1035, 168.5621, 161.7333,  ..., 140.2237, 147.7261, 151.1669],\n","        [171.2392, 171.4198, 178.4229,  ..., 197.4624, 189.0762, 189.9751],\n","        [197.5820, 199.3889, 207.3922,  ..., 223.4727, 215.6637, 213.7944]],\n","       device='cuda:0')\n","At layer idx 2 and shape torch.Size([672, 1024]), the OT cost is  126.0642666901861\n","shape of T_var is  torch.Size([336, 672])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([672])\n","inverse marginals beta is  tensor([0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015], device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999328255653381, min 0.0, mean 0.002975990530103445, std 0.05446968972682953 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 475.143798828125 \n","Shape of aligned wt is  torch.Size([336, 1024])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 3 ------------- \n"," \n","Previous layer shape is  torch.Size([672, 1024])\n","In layer _gnn._conv_layers.1.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 140.65679931640625, Mean : 132.31576538085938, Min : 124.96220397949219, Std: 2.6664247512817383\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([512, 672])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([512, 12784])\n","shape of previous transport map torch.Size([336, 672])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 80.5296,  79.9144,  78.7082,  ...,  79.6777,  79.4861,  79.5663],\n","        [ 91.1831,  90.3833,  85.2002,  ...,  86.5265,  88.6285,  88.0001],\n","        [277.2790, 276.7527, 272.2596,  ..., 273.4259, 275.4415, 274.6495],\n","        ...,\n","        [ 82.2552,  79.9088,  76.4541,  ...,  78.9915,  79.5214,  79.0901],\n","        [146.1311, 144.1952, 140.6819,  ..., 141.9861, 143.7418, 143.2094],\n","        [ 97.0467,  97.9678,  97.1411,  ...,  95.9748,  96.7236,  96.9857]],\n","       device='cuda:0')\n","At layer idx 3 and shape torch.Size([512, 672]), the OT cost is  130.04292894154787\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 672])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 4 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 672])\n","In layer _gnn._conv_layers.2.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 690.96484375, Mean : 669.587890625, Min : 655.1776733398438, Std: 5.022052764892578\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([672, 1024])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([672, 12784])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  672\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[ 715.8254,  708.2141,  709.5061,  ...,  710.5190,  713.3394,\n","          717.3078],\n","        [1168.0155, 1159.3987, 1160.4122,  ..., 1162.3375, 1165.2539,\n","         1167.5188],\n","        [ 398.1087,  387.0325,  388.3417,  ...,  390.9302,  394.2476,\n","          396.5652],\n","        ...,\n","        [ 752.4847,  741.4450,  742.2698,  ...,  744.9302,  748.8233,\n","          748.1790],\n","        [ 800.9112,  789.7844,  790.8750,  ...,  793.8358,  797.2820,\n","          799.3668],\n","        [ 810.2778,  799.4650,  801.2051,  ...,  802.3566,  806.6915,\n","          812.6948]], device='cuda:0')\n","At layer idx 4 and shape torch.Size([672, 1024]), the OT cost is  666.0433471997578\n","shape of T_var is  torch.Size([336, 672])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([672])\n","inverse marginals beta is  tensor([0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015], device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999328255653381, min 0.0, mean 0.0029759907629340887, std 0.05446968972682953 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 475.1438293457031 \n","Shape of aligned wt is  torch.Size([336, 1024])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 5 ------------- \n"," \n","Previous layer shape is  torch.Size([672, 1024])\n","In layer _gnn._conv_layers.2.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 459.7037353515625, Mean : 453.41632080078125, Min : 447.4197692871094, Std: 2.0046706199645996\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([512, 672])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([512, 12784])\n","shape of previous transport map torch.Size([336, 672])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[519.6562, 516.1717, 517.4291,  ..., 516.3851, 515.7762, 514.5380],\n","        [451.7372, 450.7390, 450.8195,  ..., 450.6172, 448.8616, 450.2869],\n","        [629.4800, 625.7599, 627.2626,  ..., 626.1738, 626.0380, 624.2450],\n","        ...,\n","        [440.6437, 436.6479, 438.1035,  ..., 436.9326, 436.5878, 434.9054],\n","        [369.4171, 368.1030, 368.3484,  ..., 367.9747, 366.0458, 367.3605],\n","        [257.8234, 253.6718, 255.2402,  ..., 254.0699, 253.6439, 251.7290]],\n","       device='cuda:0')\n","At layer idx 5 and shape torch.Size([512, 672]), the OT cost is  452.7316583096981\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0.0039, device='cuda:0')\n","Here, trace is 1.4141411781311035 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 672])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 6 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 672])\n","In layer _gnn._conv_layers.3.nn.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 414.421875, Mean : 405.1497802734375, Min : 396.5360107421875, Std: 2.8643596172332764\n","shape of layer: model 0 torch.Size([336, 512])\n","shape of layer: model 1 torch.Size([672, 1024])\n","shape of activations: model 0 torch.Size([336, 12784])\n","shape of activations: model 1 torch.Size([672, 12784])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 512])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  672\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[280.0822, 282.7684, 284.3650,  ..., 273.2358, 278.6217, 273.6937],\n","        [290.3013, 293.2533, 295.8096,  ..., 283.5240, 288.8718, 283.2753],\n","        [705.0469, 704.9100, 705.5099,  ..., 706.6529, 704.8950, 706.9641],\n","        ...,\n","        [231.6305, 234.1187, 236.7335,  ..., 224.6457, 230.4348, 224.6654],\n","        [400.0062, 398.2527, 398.8830,  ..., 402.8753, 399.3299, 403.6537],\n","        [553.5353, 557.9859, 559.5946,  ..., 544.1851, 553.4177, 544.0942]],\n","       device='cuda:0')\n","At layer idx 6 and shape torch.Size([672, 1024]), the OT cost is  402.21355145318165\n","shape of T_var is  torch.Size([336, 672])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([672])\n","inverse marginals beta is  tensor([0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n","        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015], device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999328255653381, min 0.0, mean 0.0029759907629340887, std 0.05446968972682953 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 475.1438293457031 \n","Shape of aligned wt is  torch.Size([336, 1024])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 512])\n","\n","--------------- At layer index 7 ------------- \n"," \n","Previous layer shape is  torch.Size([672, 1024])\n","In layer _gnn._conv_layers.3.nn.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 269.13751220703125, Mean : 264.1859130859375, Min : 258.6253356933594, Std: 1.5647807121276855\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([512, 672])\n","shape of activations: model 0 torch.Size([256, 12784])\n","shape of activations: model 1 torch.Size([512, 12784])\n","shape of previous transport map torch.Size([336, 672])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  512\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   12784\n","# of ground metric features in 1 is   12784\n","ground metric (m0) is  tensor([[306.1988, 302.2130, 306.4948,  ..., 308.0757, 306.9206, 306.6117],\n","        [162.1411, 158.8091, 162.4695,  ..., 164.1734, 162.8774, 162.6326],\n","        [263.8091, 260.0733, 264.0967,  ..., 265.5003, 264.5118, 264.2001],\n","        ...,\n","        [407.8240, 403.5475, 408.0612,  ..., 409.4654, 408.5483, 408.1728],\n","        [175.3701, 170.7743, 175.4914,  ..., 176.8562, 176.0603, 175.6387],\n","        [228.4913, 224.6796, 228.6627,  ..., 229.9188, 229.0481, 228.6629]],\n","       device='cuda:0')\n","At layer idx 7 and shape torch.Size([512, 672]), the OT cost is  263.74116414785385\n","shape of T_var is  torch.Size([256, 512])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([512])\n","inverse marginals beta is  tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n","        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n","       device='cuda:0')\n","tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n","        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999],\n","       device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999488592147827, min 0.0, mean 0.003906050231307745, std 0.06237485632300377 \n","scale is  0.7071067811865476\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 362.0201416015625 \n","Shape of aligned wt is  torch.Size([256, 672])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 8 ------------- \n"," \n","Previous layer shape is  torch.Size([512, 672])\n","In layer _gnn._post_processing.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 356.49871826171875, Mean : 337.2593688964844, Min : 329.9403076171875, Std: 3.6000754833221436\n","shape of layer: model 0 torch.Size([336, 1041])\n","shape of layer: model 1 torch.Size([336, 2065])\n","shape of activations: model 0 torch.Size([336, 1598])\n","shape of activations: model 1 torch.Size([336, 1598])\n","shape of previous transport map torch.Size([256, 512])\n","shape of fc_layer0_weight_data torch.Size([336, 1041])\n","shape of T_var torch.Size([256, 512])\n","returns a uniform measure of cardinality:  336\n","returns a uniform measure of cardinality:  336\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   1598\n","# of ground metric features in 1 is   1598\n","ground metric (m0) is  tensor([[130.6882, 129.8611, 139.1423,  ..., 128.1893, 133.3219, 129.6504],\n","        [162.4994, 161.7237, 169.5359,  ..., 160.0958, 164.4650, 161.4603],\n","        [153.6928, 152.3237, 161.5066,  ..., 150.4276, 155.4701, 151.3355],\n","        ...,\n","        [751.2568, 750.3656, 756.1176,  ..., 749.0367, 751.7198, 748.8964],\n","        [558.8065, 557.3250, 557.8956,  ..., 556.2682, 555.6753, 553.6635],\n","        [541.2683, 540.4204, 546.7902,  ..., 539.0594, 542.6056, 539.3011]],\n","       device='cuda:0')\n","At layer idx 8 and shape torch.Size([336, 2065]), the OT cost is  334.75915598869324\n","shape of T_var is  torch.Size([336, 336])\n","T_var before correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0030, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([336])\n","inverse marginals beta is  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n","        0.0030, 0.0030, 0.0030], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","T_var stats: max 0.9999664425849915, min 0.0, mean 0.00297609088011086, std 0.05447164550423622 \n","scale is  0.7100114243871647\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 238.55581665039062 \n","Shape of aligned wt is  torch.Size([336, 2065])\n","Shape of fc_layer0_weight_data is  torch.Size([336, 1041])\n","\n","--------------- At layer index 9 ------------- \n"," \n","Previous layer shape is  torch.Size([336, 2065])\n","In layer _gnn._post_processing.2.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 355.5801696777344, Mean : 351.165283203125, Min : 347.36822509765625, Std: 1.2134898900985718\n","shape of layer: model 0 torch.Size([256, 336])\n","shape of layer: model 1 torch.Size([256, 336])\n","shape of activations: model 0 torch.Size([256, 1598])\n","shape of activations: model 1 torch.Size([256, 1598])\n","shape of previous transport map torch.Size([336, 336])\n","returns a uniform measure of cardinality:  256\n","returns a uniform measure of cardinality:  256\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   1598\n","# of ground metric features in 1 is   1598\n","ground metric (m0) is  tensor([[357.3475, 357.2835, 357.8647,  ..., 359.2668, 356.9767, 357.0120],\n","        [524.2711, 524.2401, 524.7806,  ..., 525.8340, 523.9919, 524.0319],\n","        [350.8358, 350.2121, 351.1234,  ..., 353.6051, 349.9999, 350.0424],\n","        ...,\n","        [328.1058, 328.4884, 328.7833,  ..., 329.0028, 328.2120, 328.2269],\n","        [174.8978, 174.6803, 175.3858,  ..., 176.9710, 174.5111, 174.5208],\n","        [290.4189, 290.0737, 290.8358,  ..., 291.8523, 290.1434, 290.1729]],\n","       device='cuda:0')\n","At layer idx 9 and shape torch.Size([256, 336]), the OT cost is  350.53939858078957\n","shape of T_var is  torch.Size([256, 256])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([256])\n","inverse marginals beta is  tensor([0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n","        0.0039, 0.0039, 0.0039, 0.0039], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999743700027466, min 0.0, mean 0.003906149882823229, std 0.06237669289112091 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0.0039, device='cuda:0')\n","Here, trace is 0.9999743700027466 and matrix sum is 255.99343872070312 \n","Shape of aligned wt is  torch.Size([256, 336])\n","Shape of fc_layer0_weight_data is  torch.Size([256, 336])\n","\n","--------------- At layer index 10 ------------- \n"," \n","Previous layer shape is  torch.Size([256, 336])\n","In layer _gnn._readout.0.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 80.06925964355469, Mean : 79.64828491210938, Min : 79.43888854980469, Std: 0.12872803211212158\n","shape of layer: model 0 torch.Size([128, 768])\n","shape of layer: model 1 torch.Size([128, 768])\n","shape of activations: model 0 torch.Size([128, 20])\n","shape of activations: model 1 torch.Size([128, 20])\n","shape of previous transport map torch.Size([256, 256])\n","shape of fc_layer0_weight_data torch.Size([128, 768])\n","shape of T_var torch.Size([256, 256])\n","returns a uniform measure of cardinality:  128\n","returns a uniform measure of cardinality:  128\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   20\n","# of ground metric features in 1 is   20\n","ground metric (m0) is  tensor([[ 50.3220,  50.6052,  50.3615,  ...,  50.3585,  50.5294,  50.3678],\n","        [ 78.9587,  79.1666,  78.9904,  ...,  78.9916,  79.1096,  78.9918],\n","        [150.4275, 150.6948, 150.4665,  ..., 150.4606, 150.6214, 150.4694],\n","        ...,\n","        [ 55.0468,  55.3311,  55.0835,  ...,  55.0804,  55.2544,  55.1012],\n","        [131.4435, 131.6924, 131.4812,  ..., 131.4785, 131.6246, 131.4842],\n","        [ 48.1212,  48.4063,  48.1585,  ...,  48.1527,  48.3285,  48.1698]],\n","       device='cuda:0')\n","At layer idx 10 and shape torch.Size([128, 768]), the OT cost is  79.61003339290619\n","shape of T_var is  torch.Size([128, 128])\n","T_var before correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","shape of inverse marginals beta is  torch.Size([128])\n","inverse marginals beta is  tensor([0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n","        0.0078, 0.0078], device='cuda:0')\n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000], device='cuda:0')\n","T_var after correction  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n","T_var stats: max 0.9999872446060181, min 0.0, mean 0.007812400348484516, std 0.08804396539926529 \n","scale is  1.0\n","Ratio of trace to the matrix sum:  tensor(0., device='cuda:0')\n","Here, trace is 0.0 and matrix sum is 127.99836730957031 \n","Shape of aligned wt is  torch.Size([128, 768])\n","Shape of fc_layer0_weight_data is  torch.Size([128, 768])\n","\n","--------------- At layer index 11 ------------- \n"," \n","Previous layer shape is  torch.Size([128, 768])\n","In layer _tasks.0._affine.weight: getting activation distance statistics\n","Statistics of the distance from neurons of layer 1 (averaged across nodes of layer 0): \n","\n","Max : 78.89220428466797, Mean : 78.79292297363281, Min : 78.71656799316406, Std: 0.09006353467702866\n","shape of layer: model 0 torch.Size([3, 128])\n","shape of layer: model 1 torch.Size([3, 128])\n","shape of activations: model 0 torch.Size([3, 20])\n","shape of activations: model 1 torch.Size([3, 20])\n","shape of previous transport map torch.Size([128, 128])\n","returns a uniform measure of cardinality:  3\n","returns a uniform measure of cardinality:  3\n","Refactored ground metric calc\n","inside refactored\n","Processing the coordinates to form ground_metric\n","dont leave off the squaring of the ground metric\n","# of ground metric features in 0 is   20\n","# of ground metric features in 1 is   20\n","Simple averaging of last layer weights. NO transport map needs to be computed\n"]}],"source":["models['small_seed_0_epochs_10_mapped'] = map_model(\n","    models['small_seed_0_epochs_10'], \n","    models['small_seed_1_epochs_10'], \n","    train_dataloader, \n","    args.act_num_samples\n",")\n","torch.cuda.empty_cache()\n","\n","models['large_seed_0_epochs_10_mapped'] = map_model(\n","    models['small_seed_0_epochs_10'], \n","    models['large_seed_0_epochs_10'], \n","    train_dataloader, \n","    args.act_num_samples\n",")\n","torch.cuda.empty_cache()\n","\n","models['large_seed_0_epochs_1_mapped'] = map_model(\n","    models['small_seed_0_epochs_10'], \n","    models['large_seed_0_epochs_1'], \n","    train_dataloader, \n","    args.act_num_samples\n",")\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["_gnn._conv_layers.0.nn.0.weight tensor(-0.0032, device='cuda:0') tensor(-0.0032, device='cuda:0')\n","_gnn._conv_layers.0.nn.2.weight tensor(-0.0022, device='cuda:0') tensor(-0.0022, device='cuda:0')\n","_gnn._conv_layers.1.nn.0.weight tensor(-0.0019, device='cuda:0') tensor(-0.0019, device='cuda:0')\n","_gnn._conv_layers.1.nn.2.weight tensor(-0.0049, device='cuda:0') tensor(-0.0049, device='cuda:0')\n","_gnn._conv_layers.2.nn.0.weight tensor(-0.0024, device='cuda:0') tensor(-0.0024, device='cuda:0')\n","_gnn._conv_layers.2.nn.2.weight tensor(-0.0065, device='cuda:0') tensor(-0.0065, device='cuda:0')\n","_gnn._conv_layers.3.nn.0.weight tensor(-0.0015, device='cuda:0') tensor(-0.0015, device='cuda:0')\n","_gnn._conv_layers.3.nn.2.weight tensor(-0.0047, device='cuda:0') tensor(-0.0047, device='cuda:0')\n","_gnn._post_processing.0.weight tensor(-0.0010, device='cuda:0') tensor(-0.0010, device='cuda:0')\n","_gnn._post_processing.2.weight tensor(-0.0024, device='cuda:0') tensor(-0.0024, device='cuda:0')\n","_gnn._readout.0.weight tensor(-0.0012, device='cuda:0') tensor(-0.0012, device='cuda:0')\n","_tasks.0._affine.weight tensor(-0.0050, device='cuda:0') tensor(-0.0050, device='cuda:0')\n"]}],"source":["tol = 1e-5\n","for idx, ((layer0_name, fc_layer0_weight), (layer1_name, fc_layer1_weight)) in \\\n","        enumerate(zip(models['small_seed_0_epochs_10'].named_parameters(), models['small_seed_0_epochs_10_mapped'].named_parameters())):\n","    with torch.no_grad():\n","        if not (\n","            torch.allclose(fc_layer0_weight.mean(), fc_layer1_weight.mean(), rtol=tol, atol=tol) and\n","            torch.allclose(fc_layer0_weight.abs().mean(), fc_layer1_weight.abs().mean(), rtol=tol, atol=tol) and \n","            torch.allclose((fc_layer0_weight.abs() ** 2).mean(), (fc_layer1_weight.abs() ** 2).sum() ** 0.5, rtol=tol, atol=tol)\n","        ):\n","            print(layer0_name, fc_layer0_weight.mean(), fc_layer1_weight.mean())"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# with torch.no_grad():\n","#     model_mapped._gnn._post_processing[0].weight /= 0.5 / 0.7071667\n","#     model_mapped._gnn._post_processing[2].weight /= 0.5 / 1.0000592\n","#     model_mapped._gnn._readout[0].weight /= 0.5 / 1.0000384\n","#     model_mapped._tasks[0]._affine.weight /= 0.7 / 1.0000129"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["['small_seed_0_epochs_10',\n"," 'small_seed_1_epochs_10',\n"," 'large_seed_0_epochs_10',\n"," 'large_seed_0_epochs_1',\n"," 'small_seed_0_epochs_10_mapped',\n"," 'large_seed_0_epochs_10_mapped',\n"," 'large_seed_0_epochs_1_mapped']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["models_names, models_list = [], []\n","for model_name, model in models.items():\n","    models_names.append(model_name)\n","    models_list.append(model)\n","models_names"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.0.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.1.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.2.nn.2\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.0\n","set forward hook for layer named:  _gnn._conv_layers.3.nn.2\n","set forward hook for layer named:  _gnn._post_processing.0\n","set forward hook for layer named:  _gnn._post_processing.2\n","set forward hook for layer named:  _gnn._readout.0\n","set forward hook for layer named:  _tasks.0._affine\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:56 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:56 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:56 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:56 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:56 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:54:56 - KNNGraphBuilder.info - WARNING: GraphBuilder received graph with pre-existing structure. Will overwrite.\u001b[0m\n","num_personal_idx  0\n","model_name is  mlpnet\n","***********\n","min of act: -1.1325409412384033, max: 1.041191577911377, mean: -0.08256817609071732\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -0.9590854644775391, max: 0.9545164108276367, mean: -0.03809298574924469\n","activations for idx 0 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -17.302310943603516, max: 24.802785873413086, mean: -0.6187565326690674\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -23.767759323120117, max: 27.966617584228516, mean: -0.5973536968231201\n","activations for idx 0 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -227.50363159179688, max: 169.9368133544922, mean: -3.1012747287750244\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -117.22239685058594, max: 66.76261901855469, mean: -2.4172213077545166\n","activations for idx 0 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -76.52189636230469, max: 73.85053253173828, mean: -1.2584871053695679\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -73.33060455322266, max: 23.286928176879883, mean: -1.3345074653625488\n","activations for idx 0 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -238.05897521972656, max: 393.1527099609375, mean: -4.286755561828613\n","activations for idx 0 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -225.53236389160156, max: 62.71070098876953, mean: -4.752849578857422\n","activations for idx 0 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -76.27462005615234, max: 62.717384338378906, mean: -13.919058799743652\n","activations for idx 0 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -111.15362548828125, max: 2.1177978515625, mean: -4.961073875427246\n","activations for idx 0 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.3195627927780151, max: 1.1776950359344482, mean: -0.09055200219154358\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -1.3239096403121948, max: 1.0020647048950195, mean: -0.04542992264032364\n","activations for idx 1 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -15.780617713928223, max: 14.60289478302002, mean: -0.5592504143714905\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -15.729146957397461, max: 14.771148681640625, mean: -0.6368424296379089\n","activations for idx 1 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -74.51190185546875, max: 79.33740234375, mean: -2.2491962909698486\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -56.2629508972168, max: 37.11320114135742, mean: -1.9851322174072266\n","activations for idx 1 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -57.66425704956055, max: 63.74407958984375, mean: -1.776551365852356\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -42.308353424072266, max: 18.800479888916016, mean: -1.558029294013977\n","activations for idx 1 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -86.2443618774414, max: 100.25065612792969, mean: -4.028878211975098\n","activations for idx 1 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -77.88961791992188, max: 68.6219482421875, mean: -4.774507522583008\n","activations for idx 1 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -56.87553024291992, max: 48.92001724243164, mean: -10.3360013961792\n","activations for idx 1 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -119.71365356445312, max: 1.428957223892212, mean: -4.905736446380615\n","activations for idx 1 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.1998363733291626, max: 1.0438960790634155, mean: -0.08504427969455719\n","activations for idx 2 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -1.461012601852417, max: 1.2009639739990234, mean: -0.06599871814250946\n","activations for idx 2 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 512])\n","-----------\n","***********\n","min of act: -15.009547233581543, max: 10.419257164001465, mean: -0.6172375679016113\n","activations for idx 2 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -12.513638496398926, max: 15.264679908752441, mean: -0.5694918632507324\n","activations for idx 2 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -98.17100524902344, max: 91.93549346923828, mean: -2.6535470485687256\n","activations for idx 2 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -80.1131362915039, max: 51.153465270996094, mean: -2.355632781982422\n","activations for idx 2 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -56.180816650390625, max: 73.3470687866211, mean: -1.2438921928405762\n","activations for idx 2 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -65.31316375732422, max: 45.30332946777344, mean: -1.8433563709259033\n","activations for idx 2 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -138.93946838378906, max: 185.6753692626953, mean: -6.390253067016602\n","activations for idx 2 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -107.00570678710938, max: 57.30133819580078, mean: -4.761904239654541\n","activations for idx 2 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -72.4833755493164, max: 55.33734893798828, mean: -10.512133598327637\n","activations for idx 2 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -102.25068664550781, max: 0.9168317914009094, mean: -5.262628078460693\n","activations for idx 2 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.206117033958435, max: 1.1342575550079346, mean: 0.011200600303709507\n","activations for idx 3 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -0.6341204047203064, max: 0.40778422355651855, mean: -0.025084378197789192\n","activations for idx 3 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 512])\n","-----------\n","***********\n","min of act: -1.0388872623443604, max: 1.0029709339141846, mean: -0.046081025153398514\n","activations for idx 3 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -0.36778920888900757, max: 0.38672760128974915, mean: -0.019299069419503212\n","activations for idx 3 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -0.7410974502563477, max: 0.948723316192627, mean: -0.015333070419728756\n","activations for idx 3 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -0.318265825510025, max: 0.4013306200504303, mean: -0.008753877133131027\n","activations for idx 3 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -0.8714079260826111, max: 0.9499640464782715, mean: -0.00609301682561636\n","activations for idx 3 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -0.3247081935405731, max: 0.30105140805244446, mean: -0.004515121225267649\n","activations for idx 3 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -0.9056963920593262, max: 1.9894649982452393, mean: -0.14758174121379852\n","activations for idx 3 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -0.5171955823898315, max: 0.6803629398345947, mean: -0.01588740572333336\n","activations for idx 3 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -0.1572040170431137, max: 0.21900269389152527, mean: -0.008149252273142338\n","activations for idx 3 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -0.02662111259996891, max: 0.15974685549736023, mean: 0.024135129526257515\n","activations for idx 3 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.1325263977050781, max: 1.0411782264709473, mean: -0.08256711065769196\n","activations for idx 4 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 128])\n","-----------\n","***********\n","min of act: -0.9590364098548889, max: 0.9544676542282104, mean: -0.038091033697128296\n","activations for idx 4 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -16.116703033447266, max: 18.454345703125, mean: -0.6193647980690002\n","activations for idx 4 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -18.077966690063477, max: 16.835147857666016, mean: -0.6413464546203613\n","activations for idx 4 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -116.92057037353516, max: 120.26105499267578, mean: -3.121029853820801\n","activations for idx 4 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -86.39210510253906, max: 77.1753921508789, mean: -2.895765781402588\n","activations for idx 4 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -120.94245910644531, max: 115.77467346191406, mean: -1.6422897577285767\n","activations for idx 4 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 336])\n","-----------\n","***********\n","min of act: -122.31035614013672, max: 29.949981689453125, mean: -2.2951011657714844\n","activations for idx 4 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 256])\n","-----------\n","***********\n","min of act: -176.1556396484375, max: 329.8880615234375, mean: -5.176390171051025\n","activations for idx 4 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -166.71893310546875, max: 55.941253662109375, mean: -5.806943416595459\n","activations for idx 4 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -58.91180419921875, max: 50.83747863769531, mean: -12.145675659179688\n","activations for idx 4 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -89.91221618652344, max: 2.5361711978912354, mean: -2.9317829608917236\n","activations for idx 4 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.132511854171753, max: 1.041164517402649, mean: -0.08256605267524719\n","activations for idx 5 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -1.3562129735946655, max: 1.3497514724731445, mean: -0.05386609211564064\n","activations for idx 5 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 512])\n","-----------\n","***********\n","min of act: -17.820192337036133, max: 16.404808044433594, mean: -0.8567898273468018\n","activations for idx 5 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -17.740745544433594, max: 23.80318260192871, mean: -0.8138034343719482\n","activations for idx 5 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -181.72723388671875, max: 167.343505859375, mean: -4.149555206298828\n","activations for idx 5 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -148.0751495361328, max: 124.75006866455078, mean: -3.729580879211426\n","activations for idx 5 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -212.64625549316406, max: 200.29147338867188, mean: -2.091503858566284\n","activations for idx 5 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -202.748046875, max: 46.07996368408203, mean: -2.149179220199585\n","activations for idx 5 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -307.1241455078125, max: 598.8267822265625, mean: -6.886116981506348\n","activations for idx 5 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -217.28416442871094, max: 59.275428771972656, mean: -5.1478800773620605\n","activations for idx 5 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -59.155303955078125, max: 37.3971061706543, mean: -13.230319023132324\n","activations for idx 5 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -64.56726837158203, max: 1.9042147397994995, mean: -2.180382490158081\n","activations for idx 5 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","***********\n","min of act: -1.132511854171753, max: 1.041164517402649, mean: -0.08256605267524719\n","activations for idx 6 at layer _gnn._conv_layers.0.nn.0 have the following shape  torch.Size([12844, 256])\n","-----------\n","***********\n","min of act: -1.3562129735946655, max: 1.3497520685195923, mean: -0.05386609211564064\n","activations for idx 6 at layer _gnn._conv_layers.0.nn.2 have the following shape  torch.Size([12844, 512])\n","-----------\n","***********\n","min of act: -20.062095642089844, max: 19.824174880981445, mean: -0.8552695512771606\n","activations for idx 6 at layer _gnn._conv_layers.1.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -22.257930755615234, max: 25.63561248779297, mean: -0.8552992343902588\n","activations for idx 6 at layer _gnn._conv_layers.1.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -177.90182495117188, max: 141.49508666992188, mean: -4.321289539337158\n","activations for idx 6 at layer _gnn._conv_layers.2.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -124.60845184326172, max: 92.8782958984375, mean: -3.597132921218872\n","activations for idx 6 at layer _gnn._conv_layers.2.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -132.79974365234375, max: 178.89845275878906, mean: -2.1118340492248535\n","activations for idx 6 at layer _gnn._conv_layers.3.nn.0 have the following shape  torch.Size([12784, 672])\n","-----------\n","***********\n","min of act: -126.39256286621094, max: 48.00146484375, mean: -2.6393280029296875\n","activations for idx 6 at layer _gnn._conv_layers.3.nn.2 have the following shape  torch.Size([12784, 512])\n","-----------\n","***********\n","min of act: -253.62925720214844, max: 450.9942321777344, mean: -6.691418647766113\n","activations for idx 6 at layer _gnn._post_processing.0 have the following shape  torch.Size([1598, 336])\n","-----------\n","***********\n","min of act: -172.63006591796875, max: 51.52873229980469, mean: -5.30405855178833\n","activations for idx 6 at layer _gnn._post_processing.2 have the following shape  torch.Size([1598, 256])\n","-----------\n","***********\n","min of act: -59.5406608581543, max: 46.935035705566406, mean: -9.876922607421875\n","activations for idx 6 at layer _gnn._readout.0 have the following shape  torch.Size([20, 128])\n","-----------\n","***********\n","min of act: -63.55058670043945, max: 1.849314570426941, mean: -2.8924200534820557\n","activations for idx 6 at layer _tasks.0._affine have the following shape  torch.Size([20, 3])\n","-----------\n","_gnn._conv_layers.0.nn.0 [torch.Size([12844, 128]), torch.Size([12844, 128]), torch.Size([12844, 256]), torch.Size([12844, 256]), torch.Size([12844, 128]), torch.Size([12844, 256]), torch.Size([12844, 256])]\n","_gnn._conv_layers.0.nn.0 [-1.1325409412384033, -1.3195627927780151, -1.1998363733291626, -1.206117033958435, -1.1325263977050781, -1.132511854171753, -1.132511854171753]\n","_gnn._conv_layers.0.nn.0 [1.041191577911377, 1.1776950359344482, 1.0438960790634155, 1.1342575550079346, 1.0411782264709473, 1.041164517402649, 1.041164517402649]\n","_gnn._conv_layers.0.nn.0 [1, 0.2438115030527115, 0.2332710325717926, 0.26572275161743164, 0.24984002113342285, 0.2498367875814438, 0.2498367875814438]\n","\n","_gnn._conv_layers.0.nn.2 [torch.Size([12844, 256]), torch.Size([12844, 256]), torch.Size([12844, 512]), torch.Size([12844, 512]), torch.Size([12844, 256]), torch.Size([12844, 512]), torch.Size([12844, 512])]\n","_gnn._conv_layers.0.nn.2 [-0.9590854644775391, -1.3239096403121948, -1.461012601852417, -0.6341204047203064, -0.9590364098548889, -1.3562129735946655, -1.3562129735946655]\n","_gnn._conv_layers.0.nn.2 [0.9545164108276367, 1.0020647048950195, 1.2009639739990234, 0.40778422355651855, 0.9544676542282104, 1.3497514724731445, 1.3497520685195923]\n","_gnn._conv_layers.0.nn.2 [1, 0.139421284198761, 0.1412498652935028, 0.09755745530128479, 0.14153194427490234, 0.20014609396457672, 0.20014609396457672]\n","\n","_gnn._conv_layers.1.nn.0 [torch.Size([12784, 336]), torch.Size([12784, 336]), torch.Size([12784, 672]), torch.Size([12784, 672]), torch.Size([12784, 336]), torch.Size([12784, 672]), torch.Size([12784, 672])]\n","_gnn._conv_layers.1.nn.0 [-17.302310943603516, -15.780617713928223, -15.009547233581543, -1.0388872623443604, -16.116703033447266, -17.820192337036133, -20.062095642089844]\n","_gnn._conv_layers.1.nn.0 [24.802785873413086, 14.60289478302002, 10.419257164001465, 1.0029709339141846, 18.454345703125, 16.404808044433594, 19.824174880981445]\n","_gnn._conv_layers.1.nn.0 [1, 1.1290138959884644, 1.076123833656311, 0.17474567890167236, 1.2085144519805908, 1.5669069290161133, 1.620377540588379]\n","\n","_gnn._conv_layers.1.nn.2 [torch.Size([12784, 256]), torch.Size([12784, 256]), torch.Size([12784, 512]), torch.Size([12784, 512]), torch.Size([12784, 256]), torch.Size([12784, 512]), torch.Size([12784, 512])]\n","_gnn._conv_layers.1.nn.2 [-23.767759323120117, -15.729146957397461, -12.513638496398926, -0.36778920888900757, -18.077966690063477, -17.740745544433594, -22.257930755615234]\n","_gnn._conv_layers.1.nn.2 [27.966617584228516, 14.771148681640625, 15.264679908752441, 0.38672760128974915, 16.835147857666016, 23.80318260192871, 25.63561248779297]\n","_gnn._conv_layers.1.nn.2 [1, 1.03451406955719, 0.9543002247810364, 0.05570679157972336, 1.20526921749115, 1.4421417713165283, 1.5334089994430542]\n","\n","_gnn._conv_layers.2.nn.0 [torch.Size([12784, 336]), torch.Size([12784, 336]), torch.Size([12784, 672]), torch.Size([12784, 672]), torch.Size([12784, 336]), torch.Size([12784, 672]), torch.Size([12784, 672])]\n","_gnn._conv_layers.2.nn.0 [-227.50363159179688, -74.51190185546875, -98.17100524902344, -0.7410974502563477, -116.92057037353516, -181.72723388671875, -177.90182495117188]\n","_gnn._conv_layers.2.nn.0 [169.9368133544922, 79.33740234375, 91.93549346923828, 0.948723316192627, 120.26105499267578, 167.343505859375, 141.49508666992188]\n","_gnn._conv_layers.2.nn.0 [1, 4.220077037811279, 4.533061981201172, 0.11002852767705917, 5.768553256988525, 7.488373756408691, 7.385558605194092]\n","\n","_gnn._conv_layers.2.nn.2 [torch.Size([12784, 256]), torch.Size([12784, 256]), torch.Size([12784, 512]), torch.Size([12784, 512]), torch.Size([12784, 256]), torch.Size([12784, 512]), torch.Size([12784, 512])]\n","_gnn._conv_layers.2.nn.2 [-117.22239685058594, -56.2629508972168, -80.1131362915039, -0.318265825510025, -86.39210510253906, -148.0751495361328, -124.60845184326172]\n","_gnn._conv_layers.2.nn.2 [66.76261901855469, 37.11320114135742, 51.153465270996094, 0.4013306200504303, 77.1753921508789, 124.75006866455078, 92.8782958984375]\n","_gnn._conv_layers.2.nn.2 [1, 2.809694290161133, 3.3555619716644287, 0.04017408564686775, 4.561007976531982, 6.0012311935424805, 5.231265068054199]\n","\n","_gnn._conv_layers.3.nn.0 [torch.Size([12784, 336]), torch.Size([12784, 336]), torch.Size([12784, 672]), torch.Size([12784, 672]), torch.Size([12784, 336]), torch.Size([12784, 672]), torch.Size([12784, 672])]\n","_gnn._conv_layers.3.nn.0 [-76.52189636230469, -57.66425704956055, -56.180816650390625, -0.8714079260826111, -120.94245910644531, -212.64625549316406, -132.79974365234375]\n","_gnn._conv_layers.3.nn.0 [73.85053253173828, 63.74407958984375, 73.3470687866211, 0.9499640464782715, 115.77467346191406, 200.29147338867188, 178.89845275878906]\n","_gnn._conv_layers.3.nn.0 [1, 4.191163539886475, 4.266458988189697, 0.0879940316081047, 6.497610092163086, 7.011909008026123, 7.1908135414123535]\n","\n","_gnn._conv_layers.3.nn.2 [torch.Size([12784, 256]), torch.Size([12784, 256]), torch.Size([12784, 512]), torch.Size([12784, 512]), torch.Size([12784, 256]), torch.Size([12784, 512]), torch.Size([12784, 512])]\n","_gnn._conv_layers.3.nn.2 [-73.33060455322266, -42.308353424072266, -65.31316375732422, -0.3247081935405731, -122.31035614013672, -202.748046875, -126.39256286621094]\n","_gnn._conv_layers.3.nn.2 [23.286928176879883, 18.800479888916016, 45.30332946777344, 0.30105140805244446, 29.949981689453125, 46.07996368408203, 48.00146484375]\n","_gnn._conv_layers.3.nn.2 [1, 2.0443167686462402, 2.5122554302215576, 0.03280065953731537, 4.575204372406006, 4.671992778778076, 4.793144226074219]\n","\n","_gnn._post_processing.0 [torch.Size([1598, 336]), torch.Size([1598, 336]), torch.Size([1598, 336]), torch.Size([1598, 336]), torch.Size([1598, 336]), torch.Size([1598, 336]), torch.Size([1598, 336])]\n","_gnn._post_processing.0 [-238.05897521972656, -86.2443618774414, -138.93946838378906, -0.9056963920593262, -176.1556396484375, -307.1241455078125, -253.62925720214844]\n","_gnn._post_processing.0 [393.1527099609375, 100.25065612792969, 185.6753692626953, 1.9894649982452393, 329.8880615234375, 598.8267822265625, 450.9942321777344]\n","_gnn._post_processing.0 [1, 8.130167961120605, 11.745290756225586, 0.18045485019683838, 11.297235488891602, 15.101680755615234, 14.498828887939453]\n","\n","_gnn._post_processing.2 [torch.Size([1598, 256]), torch.Size([1598, 256]), torch.Size([1598, 256]), torch.Size([1598, 256]), torch.Size([1598, 256]), torch.Size([1598, 256]), torch.Size([1598, 256])]\n","_gnn._post_processing.2 [-225.53236389160156, -77.88961791992188, -107.00570678710938, -0.5171955823898315, -166.71893310546875, -217.28416442871094, -172.63006591796875]\n","_gnn._post_processing.2 [62.71070098876953, 68.6219482421875, 57.30133819580078, 0.6803629398345947, 55.941253662109375, 59.275428771972656, 51.52873229980469]\n","_gnn._post_processing.2 [1, 7.016521453857422, 8.054686546325684, 0.06228949502110481, 10.085084915161133, 9.647448539733887, 9.265881538391113]\n","\n","_gnn._readout.0 [torch.Size([20, 128]), torch.Size([20, 128]), torch.Size([20, 128]), torch.Size([20, 128]), torch.Size([20, 128]), torch.Size([20, 128]), torch.Size([20, 128])]\n","_gnn._readout.0 [-76.27462005615234, -56.87553024291992, -72.4833755493164, -0.1572040170431137, -58.91180419921875, -59.155303955078125, -59.5406608581543]\n","_gnn._readout.0 [62.717384338378906, 48.92001724243164, 55.33734893798828, 0.21900269389152527, 50.83747863769531, 37.3971061706543, 46.935035705566406]\n","_gnn._readout.0 [1, 11.858367919921875, 12.735139846801758, 0.03765346482396126, 11.774590492248535, 11.957568168640137, 9.598999977111816]\n","\n","_tasks.0._affine [torch.Size([20, 3]), torch.Size([20, 3]), torch.Size([20, 3]), torch.Size([20, 3]), torch.Size([20, 3]), torch.Size([20, 3]), torch.Size([20, 3])]\n","_tasks.0._affine [-111.15362548828125, -119.71365356445312, -102.25068664550781, -0.02662111259996891, -89.91221618652344, -64.56726837158203, -63.55058670043945]\n","_tasks.0._affine [2.1177978515625, 1.428957223892212, 0.9168317914009094, 0.15974685549736023, 2.5361711978912354, 1.9042147397994995, 1.849314570426941]\n","_tasks.0._affine [1, 18.778657913208008, 19.444307327270508, 0.038769979029893875, 12.09326171875, 8.98287296295166, 10.149824142456055]\n","\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAz8AAAHeCAYAAAC10rVNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBGElEQVR4nO3dfXRU9Z3H8U8SzEDEBCQQDKKRotagJhEhRauARmOqWEC7tGsV4p7ockhbGx8KtQWxKHYFliOOS0vLg0etqW2NbbFUTW2plgqioawBitsg+EAoUAiJNkhy9w/KyJgAmcwkM9/ffb/OyeFkcjP3l3lnwnwzd26SPM/zBAAAAACOS473AgAAAACgOzD8AAAAAPAFhh8AAAAAvsDwAwAAAMAXGH4AAAAA+ALDDwAAAABfYPgBAAAA4AsMPwAAAAB8geEHAAAAgC8w/AAA4ionJ0dTpkyJ9zIAAD7A8AMAQBfZsWOHZs+erZEjR6pv377KzMzUmDFj9NJLL8V7aWH27Nmjhx9+WJdffrn69++vPn366HOf+5wqKyvjvTQAiCmGHwAAushzzz2n73//+xo6dKjmzJmj7373uzpw4ICuuuoqLVu2LN7LC1mzZo3uvfdenXrqqfrOd76jBx54QGlpafryl7+sWbNmxXt5ABAzSZ7nefFeBADAv3JycjRmzBgtX7483ktp49ChQ2ptbVVqamqnPv+tt95SVlaWMjMzQ5c1NzcrPz9fjY2N2rFjR6yWGpW6ujolJyfrzDPPDF3meZ6Kior06quvas+ePTr55JPjuEIAiA2e+QGAo+zZs0c333yz0tPT1adPH02ePFkbNmxQUlJS2IPzKVOmqHfv3nrvvfc0fvx49e7dW/3799ddd92llpaW0Hbbtm1TUlKS5s2bpx/+8If6zGc+o0AgoBEjRmjdunUxW/cTTzyhkSNHKi0tTX379tXll1+uF154IWybxx57TMOGDVMgEFB2dramTZumffv2hW0zZswYnX/++aqtrdXYsWOVlpamQYMG6b/+679C29TX16tHjx6aPXt2m3Vs2bJFSUlJevTRRzv9tezdu1d33XWXLrjgAvXu3Vvp6ekqKSnRhg0bQts0Njbq5JNP1je+8Y02n//uu+8qJSVFc+fODV22b98+3XHHHRo8eLACgYCGDh2q73//+2ptbQ1tc3SrhQsXhlrV1tZKkhYtWqRhw4aFbuOLL75YTz311HG/lmHDhoUNPpIUCAT0hS98Qe+++64OHDhw3M9fvny5kpKS9Oqrr6qiokL9+/fXySefrAkTJujvf/972LY5OTm67rrr9Morr2jkyJHq2bOnhgwZoscff/y4+5Cks846K2zwkaSkpCSNHz9ezc3N+tvf/nbC6wAACxh+AOBfWltbNW7cOP3kJz/R5MmT9cADD+iDDz7Q5MmT292+paVFxcXF6tevn+bNm6fRo0dr/vz5+uEPf9hm26eeekoPP/ywbr/9ds2ZM0fbtm3TxIkT9fHHH0e97tmzZ+vmm2/WSSedpPvvv1+zZ8/W4MGD9bvf/S60zX333adp06YpOztb8+fP1w033KAf/OAHuvrqq9us4R//+IeuueYa5eXlaf78+frsZz+rb33rW/rNb34jScrKytLo0aP105/+tM1aKisrlZKSoi996Uud/nr+9re/qaqqStddd50WLFigu+++Wxs3btTo0aP1/vvvS5J69+6tCRMmqLKyMmzYlKSf/OQn8jxPN910kyTpww8/1OjRo/XEE0/olltu0SOPPKJLL71UM2bMUEVFRZv9L1u2TIsWLdJtt92m+fPn69RTT9WSJUv09a9/Xbm5uVq4cKFmz56t/Px8vfbaa536Gnfu3Km0tDSlpaV1aPuvfe1r2rBhg2bNmqWpU6fqV7/6lcrLy9ts9/bbb+vGG2/UVVddpfnz56tv376aMmWK3nrrrU6vU1KbAQ4AzPIAAJ7ned7Pf/5zT5K3cOHC0GUtLS3eFVdc4Unyli1bFrp88uTJniTv/vvvD7uOgoICb/jw4aH36+rqPElev379vL1794Yuf+655zxJ3q9+9auo1rx161YvOTnZmzBhgtfS0hL2sdbWVs/zPG/Xrl1eamqqd/XVV4dt8+ijj3qSvKVLl4YuGz16tCfJe/zxx0OXNTc3ewMHDvRuuOGG0GU/+MEPPEnexo0bw/aZm5vrXXHFFRF9DWeeeaY3efLk0Pv//Oc/23wtdXV1XiAQCLu9f/vb33qSvN/85jdh21544YXe6NGjQ+9/73vf804++WTvr3/9a9h206dP91JSUrzt27eH9iHJS09P93bt2hW27Re/+EVv2LBhEX1dx7J161avZ8+e3s0333zCbZctW+ZJ8oqKikI9Pc/zvvnNb3opKSnevn37QpedeeaZniRv9erVoct27drlBQIB784774x4nXv27PEGDBjgXXbZZRF/LgAkKp75AYB/WbVqlU466SSVlZWFLktOTta0adOO+Tn/+Z//Gfb+ZZdd1u4hQpMmTVLfvn3DtpMU9eFEVVVVam1t1cyZM5WcHP4jPSkpSZL00ksv6eDBg7rjjjvCtikrK1N6erpWrlwZ9nm9e/fWV7/61dD7qampGjlyZNhaJ06cqB49eoSdDex///d/VVtbq0mTJkX1NQUCgdA6W1patGfPHvXu3Vvnnnuu3njjjdB2RUVFys7O1pNPPhm2hr/85S9h63/mmWd02WWXqW/fvtq9e3foraioSC0tLVq9enXY/m+44Qb1798/7LI+ffro3XffjfpQxQ8//FBf+tKX1KtXLz300EMd/rzbbrst1FM6/P3T0tKid955J2y73Nzc0PeWJPXv31/nnntuxN9nra2tuummm7Rv3z4tWrQoos8FgETG8AMA//LOO+/otNNOa3Mo0tChQ9vdvmfPnm0eJPft21f/+Mc/2mx7xhlntNlOUrvbRuL//u//lJycrNzc3GNuc+QB8rnnnht2eWpqqoYMGdLmAfTpp58e9kD7yHqPXmtmZqauvPLKsEPfKisr1aNHD02cOLHTX490+IH3f//3f+vss89WIBBQZmam+vfvr7/85S/av39/aLvk5GTddNNNqqqq0ocffihJevLJJ9WzZ8+ww+62bt2qVatWqX///mFvRUVFkqRdu3aF7f+ss85qs6Zvfetb6t27t0aOHKmzzz5b06ZN06uvvhrR19XS0qIvf/nLqq2t1c9+9jNlZ2d3+HM7+v3z6e2ObBvp99nXvvY1rVq1Sj/60Y+Ul5cX0ecCQCJj+AGATkpJSYl6Wy8BT7jZ0bV++ctf1l//+lfV1NRIkn7605/qyiuvjPr1IQ8++KAqKip0+eWX64knntBvf/tbvfjiixo2bFjYCQok6ZZbblFjY6OqqqrkeZ6eeuopXXfddcrIyAht09raqquuukovvvhiu2833HBD2HX26tWrzZrOO+88bdmyRU8//bQ+//nP6+c//7k+//nPR3Qa6LKyMv3617/W8uXLdcUVV0R0m3S0SSy+z2bPnq3HHntMDz30kG6++eaOLxIADOgR7wUAQKI488wz9fLLL+vDDz8Me/bn7bffjuOqju8zn/mMWltbVVtbq/z8/Ha3OXIWry1btmjIkCGhyw8ePKi6urrQMyCRGj9+vG6//fbQoW9//etfNWPGjE5d19F+9rOfaezYsfrxj38cdvm+ffvaDFbnn3++CgoK9OSTT+r000/X9u3b2xym9ZnPfEaNjY2d/jqPOPnkkzVp0iRNmjRJBw8e1MSJE/XAAw9oxowZ6tmz53E/9+6779ayZcu0cOFCfeUrX4lqHV0pGAzqvvvu0x133KFvfetb8V4OAMQcz/wAwL8UFxfr448/1pIlS0KXtba2KhgMdsv+9+/fr82bN4cd2nUi48ePV3Jysu6///42z4oc+W1/UVGRUlNT9cgjj4Q9A/DjH/9Y+/fv17XXXtup9fbp00fFxcX66U9/qqefflqpqakaP358p67raCkpKW2eqXjmmWf03nvvtbv9zTffrBdeeEELFy5Uv379VFJSEvbxf/u3f9OaNWv029/+ts3n7tu3T4cOHTrhmvbs2RP2fmpqqnJzc+V5XuhseR9++KE2b96s3bt3h2378MMPa968efr2t7/d7qm5j+hM/874+OOPtXnzZn3wwQdhl1dWVurrX/+6brrpJi1YsKBL1wAA8cIzPwDwL+PHj9fIkSN155136u2339ZnP/tZ/fKXv9TevXslqc3rYGLt2WefVWlpqZYtW6YpU6Z06HOGDh2qe++9V9/73vd02WWXaeLEiQoEAlq3bp2ys7M1d+5c9e/fXzNmzNDs2bN1zTXX6Prrr9eWLVv02GOPacSIEWEnB4jUpEmT9NWvflWPPfaYiouL1adPn05f1xHXXXed7r//fpWWluqSSy7Rxo0b9eSTT4Y9a3W0f//3f9c999yjZ599VlOnTtVJJ50U9vG7775bv/zlL3XddddpypQpGj58uJqamrRx40b97Gc/07Zt2054qN7VV1+tgQMH6tJLL1VWVpY2bdqkRx99VNdee61OOeUUSdLatWs1duxYzZo1S/fdd5+kw03vuecenX322TrvvPP0xBNPhF3vVVddpaysrNC2kfbvjPfee0/nnXeeJk+eHPrbVWvXrtUtt9yifv366corrww7iYQkXXLJJce8/QHAEoYfAPiXlJQUrVy5Ut/4xje0YsUKJScna8KECZo1a5YuvfTSEx7aFC/333+/zjrrLC1atEj33nuv0tLSdOGFF4a9XuO+++5T//799eijj+qb3/ymTj31VN1222168MEH2wwLkbj++uvVq1cvHThwIOqzvB3x7W9/W01NTXrqqadUWVmpiy66SCtXrtT06dPb3T4rK0tXX321nn/++XZfo5KWlqY//OEPevDBB/XMM8/o8ccfV3p6us455xzNnj077PVBx3L77bfrySef1IIFC9TY2KjTTz9dX//61/Wd73znuJ935A+zbt26td21vfzyy6HhJ55qa2t18OBB/f3vf9ett97a5uPLli1j+AHghCQvEV9tCwAJpKqqShMmTNArr7yiSy+9NN7LQTsmTJigjRs3JvTrswAA8cdrfgDgKB999FHY+y0tLVq0aJHS09N10UUXxWlVOJ4PPvhAK1eu5MxkAIAT4rA3AL7Q0tKiv//978fdpnfv3rrjjjv00UcfadSoUWpubtYvfvEL/elPf9KDDz7Y7imQu9LOnTuP+/FevXp16JCteOnq9dfV1enVV1/Vj370I5100km6/fbbO31dAAB/4LA3AL6wbdu2dv945dFmzZqlc845R/Pnz9fbb7+tf/7znxo6dKimTp2q8vLyblrpJ050goWjX7CeiLp6/cuXL1dpaanOOOMMzZ8/XzfeeGOnrwsA4A8MPwB84Z///KdeeeWV424zZMiQhHpR90svvXTcj2dnZys3N7ebVhM56+sHALiH4QcAAACAL3DCAwAAAAC+wPADAAAAwBcYfgAAAAD4AsMPAAAAAF9g+AEAAADgCww/AAAAAHyB4QcAAACALzD8AAAAAPAFhh8AAAAAvsDwAwAAAMAXGH4AAAAA+ALDDwAAAABfYPgBAAAA4AsMPwAAAAB8geEHAAAAgC8w/AAAAADwBYYfAAAAAL7A8AMAAADAFxh+AAAAAPgCww8AAAAAX2D4AQAAAOALDD8AAAAAfIHhBwAAAIAvMPwAAAAA8AWGHwAAAAC+wPADAAAAwBcYfgAAAAD4AsMPAAAAAF/oEe8FRKq1tVXvv/++TjnlFCUlJcV7Ob7ieZ4OHDig7OxsJSd3fm6mYfzEqqFEx3ihoRvoaB8N3UBH+yJtaG74ef/99zV48OB4L8PXduzYodNPP73Tn0/D+Iu2oUTHeKOhG+hoHw3dQEf7OtrQ3PBzyimnSDr8Baanp8d5Nf7S0NCgwYMHhxp0Fg3jJ1YNJTrGCw3dQEf7aOgGOtoXaUMzw08wGFQwGFRLS4skKT09nW+sOOnsU7k0TBzRPB1Px8RAQzfQ0T4auoGO9nW0YZLneV4XryWmGhoalJGRof379/ON1c1iddvTMH5iedvTMT5o6AY62kdDN9DRvkhvd872BgAAAMAXGH4AAAAA+ALDDwAAAABfMDP8BINB5ebmasSIEfFeCjqJhm6go300dAMd7aOhG+hoCyc8QIdxwgP7eGGnfTR0Ax3to6Eb6GgfJzwAAAAAgHYw/AAAAADwBYYfAAAAAL5gZvjhxWT20dANdLSPhm6go300dAMdbeGEB+gwTnhgHy/stI+GbqCjfTR0Ax3t44QHAAAAANAOhh8AAAAAvsDwAwAAAMAXGH4AAAAA+ALDDwAAAGIiZ/rKeC8BOC4zww+nEbSPhm6go300dAMd7aOhG+hoC6e6Rodxqmv7OKWnfTR0Ax3to2H7cqav1LaHro33MjqMjvZxqmsAAAAAaAfDDwAAAABfYPgBAAAA4AsMPwB8j7MTAQDgDww/AAAAAHyB4QcAAACALzD8AAAAAPAFhh8AAAAAvmBm+OGv59pHQzfQ0T4auoGO9tHQDXS0JcnzPC/ei4gEfz03fmJ129MwfvhL1u2z9BfJaegGOtpHw/ZZ+nkq0dEFkd7uZp75AQAAAIBoMPwAAAAA8AWGHwAAAAC+wPADAAAAwBcYfgAAAAD4AsMPAAAAAF9g+AEAAADgCww/AAAAAHyB4QcAAACALzD8AAAAAPCFuAw/dXV1Gjt2rHJzc3XBBReoqakpHssAAAAAcJSc6SvjvYQu1SMeO50yZYrmzJmjyy67THv37lUgEIjHMgAAAAD4SLc/8/PWW2/ppJNO0mWXXSZJOvXUU9WjR1xmsLhzfbIGACAS/L8IoKtFPPysXr1a48aNU3Z2tpKSklRVVdVmm2AwqJycHPXs2VOFhYVau3Zt6GNbt25V7969NW7cOF100UV68MEHo/oCAAAAEH9HhleGWCSyiJ9yaWpqUl5enm699VZNnDixzccrKytVUVGhxYsXq7CwUAsXLlRxcbG2bNmiAQMG6NChQ/rjH/+ompoaDRgwQNdcc41GjBihq666qt39NTc3q7m5OfR+Q0NDpEtGnNHQDXS0j4ZuoKN9NHQDHW2K+JmfkpISzZkzRxMmTGj34wsWLFBZWZlKS0uVm5urxYsXKy0tTUuXLpUkDRo0SBdffLEGDx6sQCCgL3zhC6qpqTnm/ubOnauMjIzQ2+DBgyNdMuKMhm6go300dAMd7aOhG+hoU0xf83Pw4EGtX79eRUVFn+wgOVlFRUVas2aNJGnEiBHatWuX/vGPf6i1tVWrV6/Weeedd8zrnDFjhvbv3x9627FjRyyXjG5AQzfQ0T4auoGO9tHQDXS0KaZnGti9e7daWlqUlZUVdnlWVpY2b958eIc9eujBBx/U5ZdfLs/zdPXVV+u666475nUGAgHOBmccDd1AR/to6AY62kdDN7jcMWf6Sm176Np4L6NLxOU0ayUlJSopKYnoc4LBoILBoFpaWrpoVehqNHQDHe2joRvoaB8N3UBHW2J62FtmZqZSUlJUX18fdnl9fb0GDhwY1XVPmzZNtbW1WrduXVTXg/ihoRvoaB8N3UBH+2joBjraEtPhJzU1VcOHD1d1dXXostbWVlVXV2vUqFGx3BUAAAAARCTi4aexsVE1NTWhM7TV1dWppqZG27dvlyRVVFRoyZIlWrFihTZt2qSpU6eqqalJpaWlUS00GAwqNzdXI0aMiOp6ED80dAMd7aOhG+hoHw3dQEdbkjzP8yL5hN///vcaO3Zsm8snT56s5cuXS5IeffRRPfzww9q5c6fy8/P1yCOPqLCwMCYLbmhoUEZGhvbv36/09PSYXGe8WHsxWaxue5caWhPL296ljpbuizR0Ax3bx33RdsOj/7gpHe13dLVhxCc8GDNmjE40L5WXl6u8vDzSqwYAAACALhPT1/x0JZ5StI+GbqCjfTR0Ax3to6Eb6GiLmeGHM2nYR0M30NE+GrqBjvbR0A10tMXM8AMAAAAA0WD4AQAAAOALZoYfjqe0j4ZuoKN9NHQDHe2joRvoaIuZ4YfjKe2joRvoaB8N3UBH+2joBpc6Hn26cleZGX4AAAAAIBoMPwAAAAB8wczww/GU9tHQDXS0j4ZuoKN9NHQDHW0xM/y4dDylX9HQDXS0j4ZuoKN9NHQDHW0xM/wAAAAAQDQYfgAAAAD4AsMPAF/zw2k9AaCr8bMUVpgZfngxmX0uNvTjD3sXO/oNDd1AR/to6AY62mJm+HHtxWR+fNDsWkO/oqN9NHQDHe2joRvoaIuZ4QcAALjLj78UBND9GH4AAAAA+ALDDwAAAABfYPgBosShGgAAADYw/AAAAADwBYYfAAAAAL5gZvjhHOr20dANdLSPhm6go300dAMdbTEz/HAOdfto6AY62kdDN9DRPhq6gY62mBl+AAAAACAaDD8AAAAAfIHhBwAAAIAvMPwAAAAA8AWGHwAAAAC+wPADAACATsuZvjLeSwA6jOEHAAAAgC+YGX74A1L20dANdLSPhm6go300dAMdbTEz/PAHpOyjoRvoaB8N3UBH+2joBjraYmb4AQAAANA1/PLaLYYfAAAAAL7A8AMAAADAFxh+AAAAAPgCww8AAAAAX2D4AQAAAOALDD8AfMsvZ7YBAACHMfwAAAAA8AWGHwAAAAC+wPADAAAAwBfiMvzk5OTowgsvVH5+vsaOHRuPJSQMXnMAAACAePLT49Ee8drxn/70J/Xu3TteuwcAAABwDDnTV2rbQ9fGexkxx2FvAAAgrvz0W2cA8RXx8LN69WqNGzdO2dnZSkpKUlVVVZttgsGgcnJy1LNnTxUWFmrt2rVhH09KStLo0aM1YsQIPfnkk51ePAAAAAB0VMSHvTU1NSkvL0+33nqrJk6c2ObjlZWVqqio0OLFi1VYWKiFCxequLhYW7Zs0YABAyRJr7zyigYNGqQPPvhARUVFuuCCC3ThhRe2u7/m5mY1NzeH3m9oaIh0yYgzGrqBjvbR0A10tI+GbqCjTRE/81NSUqI5c+ZowoQJ7X58wYIFKisrU2lpqXJzc7V48WKlpaVp6dKloW0GDRokSTrttNP0hS98QW+88cYx9zd37lxlZGSE3gYPHhzpkhFnNHQDHe2joRvoaB8N3UBHm2L6mp+DBw9q/fr1Kioq+mQHyckqKirSmjVrJB1+5ujAgQOSpMbGRv3ud7/TsGHDjnmdM2bM0P79+0NvO3bsiOWS0Q1o6AY62kdDN9DRPhq6gY42xfRsb7t371ZLS4uysrLCLs/KytLmzZslSfX19aFnjVpaWlRWVqYRI0Yc8zoDgYACgUAsl4luRkM30NE+GrqBjvb5oaGrZwo7mh86uqjbT3U9ZMgQbdiwIeLPCwaDCgaDamlp6YJVoTvQ0A10tI+GbqCjfTR0Ax1tielhb5mZmUpJSVF9fX3Y5fX19Ro4cGBU1z1t2jTV1tZq3bp1UV0P4oeGbqCjfTR0Ax3to6Eb6GhLTIef1NRUDR8+XNXV1aHLWltbVV1drVGjRsVyV6bx9wwAAIALeEwDayIefhobG1VTU6OamhpJUl1dnWpqarR9+3ZJUkVFhZYsWaIVK1Zo06ZNmjp1qpqamlRaWhrVQoPBoHJzc4/7+iAkNhq6gY720dANdLSPhm6goy0RDz+vv/66CgoKVFBQIOnwsFNQUKCZM2dKkiZNmqR58+Zp5syZys/PV01NjVatWtXmJAiR4ilF+2joBlc7+um3l6429Bs62kdDN9DRlohPeDBmzBh5nnfcbcrLy1VeXt7pRQEAAABArMX0NT9diacU7aOhG+hoHw3dQEf7aOgGOtpiZvjhKUX7XGvop8OkjuZaRz+ioRvoaB8N3UBHW8wMPwAAAAAQDYYfAAAAAL5gZvjheEr7aOgGOtpHQzfQ0T4auoGOtpgZfjie0j4auoGO9tHQDXS0j4ZuoKMtZoYfAAAAJA6/nvjHNX7ryPADAAAAwBfMDD8cT2kfDd1AR/to6AZXOvrtt85Hc6Wh39HRFjPDD8dT2kdDN9DRPhq6gY720dANdLTFzPADAAAAANFg+AHgS34+1AYAAL9i+AEAAADgCww/AAAAAHzBzPDDmTTso6Eb6GgfDd1AR/to6AY62mJm+OFMGvbR0A10tI+GbqCjfZYb8rrJT9DRFjPDDwAAAABEg+EHAAAAgC8w/AAAAADwBYYfAAAAAL7A8AMAAADAF8wMP5xG0D4auoGO9tHQDXS0j4ZuoKMtZoYfy6cRxGE0dAMd7aOhG1zt6KdT77ra0G/oaIuZ4ccVfvqhDgAA3MNjGTf4tSPDDwAAiAu/PvgCED8MPwAAAAB8geEHiAF+ewkAAJD4GH6ATmDYAQAAsIfhBwAAAIAvMPwA8B2euQMAwJ8YfgAAAAD4gpnhh7+eax8N3UBH+2joBjraZ7Ehz5y3ZbGjn5kZfvjrufbR0A10tI+GbqCjfTR0Ax1tMTP8AAAAAEA0GH4AAAAA+ALDDwAAAABfYPgBAAAA4AsMPwAAAADacPHsfgw/AACg27n4oAqwws/3P4YfAAAAnJCfHzDDHQw/AAAAAHyB4QcAAACAL8Rt+Pnwww915pln6q677orXEgD4EIdtAADgX3Ebfh544AF97nOfi9fuAQAAAPhMXIafrVu3avPmzSopKYnH7gGgXTwrBACxw89UJKKIh5/Vq1dr3Lhxys7OVlJSkqqqqtpsEwwGlZOTo549e6qwsFBr164N+/hdd92luXPndnrRAAAAACLn96E04uGnqalJeXl5CgaD7X68srJSFRUVmjVrlt544w3l5eWpuLhYu3btkiQ999xzOuecc3TOOedEt3KD/P7NBgAAAMRTj0g/oaSk5LiHqy1YsEBlZWUqLS2VJC1evFgrV67U0qVLNX36dP35z3/W008/rWeeeUaNjY36+OOPlZ6erpkzZ7Z7fc3NzWpubg6939DQEOmSEWc0dAMd7aOhG+hoHw3dQEebYvqan4MHD2r9+vUqKir6ZAfJySoqKtKaNWskSXPnztWOHTu0bds2zZs3T2VlZcccfI5sn5GREXobPHhwLJeMbkBDN9DRPhq6gY720dANdLQppsPP7t271dLSoqysrLDLs7KytHPnzk5d54wZM7R///7Q244dO2KxVHQjGrqBjvbR0A10tI+GbqCjTREf9hZLU6ZMOeE2gUBAgUCg6xeDLkNDN9DRPhq6wYWOfn8NrAsNQUerYvrMT2ZmplJSUlRfXx92eX19vQYOHBjVdQeDQeXm5mrEiBFRXQ/ih4ZuoKN9NHQDHe2joRtc7+jaLytiOvykpqZq+PDhqq6uDl3W2tqq6upqjRo1KqrrnjZtmmpra7Vu3bpol4k4oaEb6GgfDd1AR/to6AY62hLx8NPY2KiamhrV1NRIkurq6lRTU6Pt27dLkioqKrRkyRKtWLFCmzZt0tSpU9XU1BQ6+1tnuT5V+wEN3UBH+2joBjraZ6mha7/9jyVLHdGJ4ef1119XQUGBCgoKJB0edgoKCkJnbJs0aZLmzZunmTNnKj8/XzU1NVq1alWbkyBEiqnaPhq6gY720dANdLSPhm6goy0Rn/BgzJgx8jzvuNuUl5ervLy804tyEb8xAQAAAOIrpq/5QecwGAEAAABdz8zww/GU9rnS0O/Dqisd/YyGbqCjfTR0Ax1tMTP8cDylfTR0Ax3to6Eb6GiflYZ+/6XfiVjpiMPMDD8AAAAAEA0zww9PKdpHQzfQ0T4ausHljn55psHlhkf4oaWljn7ocSJmhh+eUrSPhm6go300dAMd7aOhG+hoi5nhBwAA2MdvngHEE8MPAAAAAF9g+AHgGx35jTO/lQYAwF1mhh9LLyZD+2joBjraR0M30NE+Cw35hdCJWeiIT5gZfngxmX00dAMd7aOhG+hoHw3dQEdbzAw/AAAAABANhh8AAADAcRzCeBjDDwAAAABfMDP88GIy+2joBjraR0M30NE+GrqBjraYGX4sv5iMpxkPs9wQn6CjfTR0Ax3tS/SGPH7pmETviHBmhh8AAAAA3c+lQZjhBwAAdAuXHkCh4+iORMLwA8QIP9wBAAASG8MPAF9gOAUAAAw/AAAAAHzBzPDDaQTtc6Ehzx640dHvaOgGOtqXyA35/67jErkj2jIz/HAaQfto6AY62kdDN9DRPhq6gY62mBl+AACAXTyTACARMPwAAAAA8AWGHwAAkHB4pih+uO3dQ9NPMPwAwKfwnwQAAG5i+OliPIgCAACAda48pmX4AQAAQJdy5YEz7GP4AQAAAOALDD8AAAAAfMHM8MNfz7WPhm6w2JHDLcJZbIi26GgfDd1AR1vMDD8W/3ouD7jCWWyItuhoHw3dYKkj/x+2z1JDHFuid+T+F87M8AMAAAAA0WD4AQAAAOALDD8AAACQxCFScB/DT4Lghw0AAADQtRh+AAAAAPgCww8AAAAAX2D4AQAAQJfjEH8kAoYfAAAAAL7A8AN0EL+xAgAAfubCYyGGHwAAkJBceKBlCbc3/KDbh599+/bp4osvVn5+vs4//3wtWbKku5cAwEf4zxyIL+6DQPxw/2urR3fv8JRTTtHq1auVlpampqYmnX/++Zo4caL69evX3UsBYi5n+kpte+jaeC8DAICI8CAZftHtz/ykpKQoLS1NktTc3CzP8+R5Xncvo8vxQwSwjfswAMQeP1sRbxEPP6tXr9a4ceOUnZ2tpKQkVVVVtdkmGAwqJydHPXv2VGFhodauXRv28X379ikvL0+nn3667r77bmVmZnb6CwAAAACAjoj4sLempibl5eXp1ltv1cSJE9t8vLKyUhUVFVq8eLEKCwu1cOFCFRcXa8uWLRowYIAkqU+fPtqwYYPq6+s1ceJE3XjjjcrKymp3f83NzWpubg6939DQEOmSEWc0dAMd7aOhG+hoHw3dQEebIn7mp6SkRHPmzNGECRPa/fiCBQtUVlam0tJS5ebmavHixUpLS9PSpUvbbJuVlaW8vDz98Y9/POb+5s6dq4yMjNDb4MGDI10y4oyGbqCjfTR0Ax3to6EbEr0jhxi2L6av+Tl48KDWr1+voqKiT3aQnKyioiKtWbNGklRfX68DBw5Ikvbv36/Vq1fr3HPPPeZ1zpgxQ/v37w+97dixI5ZLTiiufpP6qaHL6GgfDd1AR/to6Aa/drT+eDWmZ3vbvXu3Wlpa2hzClpWVpc2bN0uS3nnnHd12222hEx187Wtf0wUXXHDM6wwEAgoEArFcJroZDd1AR/to6AZLHa0/SOoqidaQTp2TaB3RMd1+quuRI0eqpqYm4s8LBoMKBoNqaWmJ/aLQLWjoBjraR0M30NE+GrqBjrbE9LC3zMxMpaSkqL6+Puzy+vp6DRw4MKrrnjZtmmpra7Vu3bqorgfxQ0M3WOrIbzPbZ6khjo2O9tHQDXS0JabDT2pqqoYPH67q6urQZa2traqurtaoUaNiuSsAAAAAiEjEw09jY6NqampCh67V1dWppqZG27dvlyRVVFRoyZIlWrFihTZt2qSpU6eqqalJpaWlUS00GAwqNzdXI0aMiOp6ugO/bW6fpYY4NjraR0M30NE+GrqBjrZEPPy8/vrrKigoUEFBgaTDw05BQYFmzpwpSZo0aZLmzZunmTNnKj8/XzU1NVq1atUx/45PR/GUon00dAMd7aOhG+hoHw3dQEdbIj7hwZgxY+R53nG3KS8vV3l5eacXBQAAIB0+mmLbQ9fGexkAHBHT1/x0JZ5StI+GbqCjfTR0Ax3tS4SGHKofvUToiI4zM/zwlKJ9NHQDHe2joRvoaB8N3ZCIHbt6qLU8NJsZfgAAAAAgGgw/AAAAPhSv395bftYA9pkZfjie0j4ausFPHV39D9pPDV2W6B1dvf/EUqI3RMfQ0RYzw08iHk+JyFhuyH/in7DcEYfR0A10tI+GbqCjLWaGHwAAAACIBsNPjPEMAQAAAJCYzAw/HE9pHw3dQEf7aOgGOtpHQzckWkd+EX98ZoYfjqe0j4ZuoKN9NHQDHe2joRvoaIuZ4ccCJm0gcXB/BIBj42ck/IrhBwAAAIAvMPwAAAAA8AWGHwAAEFMcUgXEB/e9EzMz/CTamTQQORq6gY720dANdLSPhm6goy1mhh/OpGEfDd3gt44u/hbNbw1d5aeOLt4PJX81dBkdbTEz/AAAAABANBh+ADjH1d8SA0AsJMLPyJzpKxNiHfAfhp8Eww+CxEMTAACAcFYfHzH8AAAAAPAFhh8AAAAAvmBm+En00whafeqvOyV6Q3QMHe2joRvoaB8N3eDnjhYf/5oZfjiNoH00dIMfO1r84X48fmzoIjraR0M30NEWM8MPAADwL9d+CQEgPhh+AAAAHHb04MgQ6SZOHd5xDD9AjPHDBwCQaPi/CTiM4QcAAMQMD7IRCb5f0N0YfmKAOy4AAAD8yNrjYIYfAAAAAL7A8AMAAOADifob+kRdF9zE8AMAAADAF8wMP37+67muoKEb6GgfDd1AR/to6AY62mJm+OGv59pHQzf4taNLh2X4taFr6GgfDd1AR1vMDD8A0BEuDSkAACC2GH4AAAAA+ALDDwAAAABfYPgBAAAx0dWHnXJYa+S4zYBwDD9R4oeK2+gLAABwfJYeLzH8AHCGpR++AABEi//3IsfwEwW+4QAAAAA7GH4AAAAQVznTV/JLZXQLhp8ExJ0fAAAAHZEojxsTZR0n0u3Dz44dOzRmzBjl5ubqwgsv1DPPPNPdSwAAAADgQ90+/PTo0UMLFy5UbW2tXnjhBd1xxx1qamrq7mUkPCvTM9pHPwDoGvx8BRCNbh9+TjvtNOXn50uSBg4cqMzMTO3du7e7lwEAAAAghiz8ciLi4Wf16tUaN26csrOzlZSUpKqqqjbbBINB5eTkqGfPniosLNTatWvbva7169erpaVFgwcPjnjhAAAAABCJiIefpqYm5eXlKRgMtvvxyspKVVRUaNasWXrjjTeUl5en4uJi7dq1K2y7vXv36pZbbtEPf/jDzq0cAAAA7bLwG3ggHnpE+gklJSUqKSk55scXLFigsrIylZaWSpIWL16slStXaunSpZo+fbokqbm5WePHj9f06dN1ySWXHHd/zc3Nam5uDr3f0NAQ6ZIRZzR0Ax3to6Eb6GgfDd1AR5ti+pqfgwcPav369SoqKvpkB8nJKioq0po1ayRJnudpypQpuuKKK3TzzTef8Drnzp2rjIyM0BuHyNlDQzfQ0T4auoGO9p/VoOGxWWpLR5tiOvzs3r1bLS0tysrKCrs8KytLO3fulCS9+uqrqqysVFVVlfLz85Wfn6+NGzce8zpnzJih/fv3h9527NgRyyWjG9DQDXS0j4ZuoKN93dXQ0iBxNCvr5r5oU8SHvUXr85//vFpbWzu8fSAQUCAQUDAYVDAYVEtLSxeuDl2Bhm6go300dEOidrTygDURJGrDRJMzfaW2PXRtvJdxTHS0KabP/GRmZiolJUX19fVhl9fX12vgwIFRXfe0adNUW1urdevWRXU9iB8auiFRO/LAq+MStSEiQ0f7aOgGOtoS0+EnNTVVw4cPV3V1deiy1tZWVVdXa9SoUbHcVdzxQAsAgPjh/2H4HfeBzol4+GlsbFRNTY1qamokSXV1daqpqdH27dslSRUVFVqyZIlWrFihTZs2aerUqWpqagqd/a2zgsGgcnNzNWLEiKiuB/FDQzfQ0T4auoGO9tHQDXS0JeLh5/XXX1dBQYEKCgokHR52CgoKNHPmTEnSpEmTNG/ePM2cOVP5+fmqqanRqlWr2pwEIVI8pWgfDd1AR/to6AY62kdDN9DRlohPeDBmzBh5nnfcbcrLy1VeXt7pRQEAADs4/AboXol8n0v0E1XE9DU/AAAAAJCozAw/fjyeMpGn+s7wY0MXJWJH1+4rXS0RGyJydLSPhm6goy1mhh+Op7SPhm7wc0dXhiw/N3QJHe2j4bFZ+nlLR1vMDD9Ad4v2B6+lH9wAAAB+YGb4SaSnFHlQ2zmJ1BCdR0f7aOgGOtrXVQ15nNK9uC/aYmb4SZSnFPmB0nmJ0hDRoaN9NHQDHe2joRvoaIuZ4QfoTgy5AAAA7mH4AWBadw+qDMYAANjF8AMAAICExS+d7EnkZmaGH15MZh8N3UBH+2joBjom9gOsjqChG+hoi5nhhxeT2UdDN9DRPhq6gY720dAN3d3R+tAfb2aGHwAAgE/jgSCASDD8AAAAAPAFhp8Ex2+0AACA3/F4CLFiZvjhxWT20dANdLSPhm6go33RNvz0QJAzfSVDQhxwX7TFzPDDiwLto6Eb6GgfDd1AR/to6AY62mJm+EkE/DYFAAAA8cJj0egx/AAAACAh8WDftkTsx/ADAAAAwBcYfgAAAAD4AsMPAADotEQ8rAUAjsXM8MNpBO2joRvoeJjlB3w0dAMdP2H1/hjLhlZvAxdwX2xfon5Pmhl+OI2gfTR0Ax3to6Eb6GgfDd1AR1vMDD/xlqjTKwAAAICOYfgBYBa/lADii/sgAGsYfgAAAAD4AsMPAAAAAF9g+AEAAIAJHGqJaDH8AECE+M8XAACbGH4AAIB5/FICSEyJdt9k+AEAAADgC2aGn3j99dyc6SsTbmK1yo9/AdnF7x0/dnQNDd1AR/ti1dDF/2vac+TrTLSvtzvui4n2NVtmZvjhr+faR0M30NE+GrqBjvbR0A10tMXM8AN0F367AgA28fMbwIkw/AAAACSgYw1zDHn+kqiH+1nF8APAJP4TAAAAkWL4AQAAAOALDD8G8BtuAAAAf+HxX9dg+AFgBv8RAACAaDD8AAAAAPAFhh8j+I03ACCR8P9SfHH7w6JE+L5l+AEAAADgCww/x5EI0ykAAACA2IjL8DNhwgT17dtXN954Yzx2DwAAAMCH4jL8fOMb39Djjz8ej10DAACYwVEoxxfJ7cNtGV+JcvvHZfgZM2aMTjnllHjsGgAAAIBPRTz8rF69WuPGjVN2draSkpJUVVXVZptgMKicnBz17NlThYWFWrt2bSzW6nuJMjG7itsXAADAbT0i/YSmpibl5eXp1ltv1cSJE9t8vLKyUhUVFVq8eLEKCwu1cOFCFRcXa8uWLRowYEDEC2xublZzc3Po/YaGhoivA/FFQzfQ0T4auoGO9tHQDXS0KeJnfkpKSjRnzhxNmDCh3Y8vWLBAZWVlKi0tVW5urhYvXqy0tDQtXbq0UwucO3euMjIyQm+DBw/u1PUgfmjoBjq2Ze3ZQhq6IRE6WvveTzSJ0NAlHfl+7Irv2Wg7+vV+9Omvu7tvh5i+5ufgwYNav369ioqKPtlBcrKKioq0Zs2aTl3njBkztH///tDbjh07YrVcdBMauoGO9tHQDXS0j4ZuoKNNER/2djy7d+9WS0uLsrKywi7PysrS5s2bQ+8XFRVpw4YNampq0umnn65nnnlGo0aNavc6A4GAAoFALJeJbkZDN9DRPhq6gY720dANdLQppsNPR7300ksRf04wGFQwGFRLS0sXrKgtvz4V2ZW6u2FH0ToyidoRHUdDN9DRPhq6gY62xPSwt8zMTKWkpKi+vj7s8vr6eg0cODCq6542bZpqa2u1bt26qK4H8UNDN9DRPhq6gY720dANdLQlpsNPamqqhg8frurq6tBlra2tqq6uPuZhbQAAAADQHSIefhobG1VTU6OamhpJUl1dnWpqarR9+3ZJUkVFhZYsWaIVK1Zo06ZNmjp1qpqamlRaWhrVQoPBoHJzczVixIiorse6nOkrzR6mRUM30NE+GrqBjvZ1pqHVxwAui+a+eKLHda70jtcZ+doT8fDz+uuvq6CgQAUFBZIODzsFBQWaOXOmJGnSpEmaN2+eZs6cqfz8fNXU1GjVqlVtToIQKZ5StI+GbqCjfTR0Ax3to6Eb6GhLxCc8GDNmjDzPO+425eXlKi8v7/SiAAAAACDWYvqan67UnU/vu/IUY6KxcIhGV7R37fsp3h1duz3jId4NERt0tI+GbqCjLWaGH55StI+GbqCjfTR0Ax3to6Eb6GiLmeEHAAAAAKLB8AMAAADAF8wMPxxPaR8N3UBH+2johnh1tPC6Oyt/FqKjDY/39Vj4OrvCsW6TeNwesbgv+rXjEd359ZsZfjie0j4auoGO9tHQDXS0j4ZuoKMtZoYfAAAAAIgGww8AAAAAXzAz/HTHsc2Wjre0tNYjeJ2BG+gYjvsi4iUeHS18v1tY4xHcF91AR1vMDD8cT2kfDd1AR/to6AY62kdDN9DRFjPDDwAAAABEg+EHAAAAgC8w/AAAAADwBYYfAAAAAL5gZvjhTBr20dAN/FV5+7gvuoGOHXP0z45E+zlyvIaJttZEd6zbqztux1jdF4+sNWf6Suf7x/PrMzP8cCYN+2joBjraR0M30NE+GrqBjraYGX4AAAAAIBoMPwAAAAB8geEHAAAAgC8w/AAAAADwBYYfAAAAAL5gZvjpqlN6Wj6VoLW1c1pWNyRCR2vf+4kmERoienS0j4ZuoKMtZoYfTiNoHw3dQEf7aOgGOtpHQzfQ0RYzww8AAAAARIPhBwAAAIAvMPwAAAAA8AWGHwAAAAC+wPADAAAAwBcYfgAAAAD4AsMPAAAAAF9g+AEAAADgC2aGn1j89dzj/VX4Ix/jL8d3HT//BWSXvq/i0THRb79EX9+n+fm+6BI6nlii/98eacNE/ToSxbF6d/XtFsv7op8a50xfGZev18zww1/PtY+GbqCjfTR0Ax3to6Eb6GiLmeEHAAAAAKLB8AMAAADAFxh+AAAAAPgCww8AAAAAX2D4AQAAAOALDD8AAAAAfIHhBwAAAIAvMPwAAAAA8AWGHwAAAAC+EJfh59e//rXOPfdcnX322frRj34UjyUAAAAA8Jke3b3DQ4cOqaKiQi+//LIyMjI0fPhwTZgwQf369evupQAAAADwkW5/5mft2rUaNmyYBg0apN69e6ukpEQvvPBCdy8DAAAAgM9EPPysXr1a48aNU3Z2tpKSklRVVdVmm2AwqJycHPXs2VOFhYVau3Zt6GPvv/++Bg0aFHp/0KBBeu+99zq3egAAAADooIiHn6amJuXl5SkYDLb78crKSlVUVGjWrFl64403lJeXp+LiYu3atSvqxQIAAABAZ0X8mp+SkhKVlJQc8+MLFixQWVmZSktLJUmLFy/WypUrtXTpUk2fPl3Z2dlhz/S89957Gjly5DGvr7m5Wc3NzaH39+/fL0lqaGiIdOlqbf6wzecduay1+cOIry8RdOZ2iHZfnudF9HmxbNgVuqt9Iny9nW0oxbejhftnd/W12hDhrHa0cF88liP/18fqdurqhpZv60Rw5Lb89O346f7xvC/SuK3O3D8jbuhFQZL37LPPht5vbm72UlJSwi7zPM+75ZZbvOuvv97zPM/7+OOPvaFDh3rvvvuud+DAAe+cc87xdu/efcx9zJo1y5PEWwK97dixI6LvExom3lukDemYeG80dOONjvbfaOjGGx3tv3W0YZLndWLU/ZekpCQ9++yzGj9+vKRPXs/zpz/9SaNGjQptd8899+gPf/iDXnvtNUnSL3/5S911111qbW3VPffco9tuu+2Y+/j0VN3a2qq9e/eqX79+SkpK6uzSQxoaGjR48GDt2LFD6enpUV+flX13Zv+e5+nAgQPKzs5WcnLHj5ikYeLsv7MNpa7taO12jOe+E7WhZOt2jPf+E7WjtdsxnvtO1IaSrdsx3vtP1I407LqG3X6qa0m6/vrrdf3113do20AgoEAgEHZZnz59Yr6m9PT0uASO974j3X9GRkbE10/DxNp/ZxpK3dPR0u0Yz30nckPJzu0Y7/0nckdLt2M8953IDSU7t2O895/IHWkY+4YxPdV1ZmamUlJSVF9fH3Z5fX29Bg4cGMtdAQAAAEBEYjr8pKamavjw4aqurg5d1traqurq6rDD4AAAAACgu0V82FtjY6Pefvvt0Pt1dXWqqanRqaeeqjPOOEMVFRWaPHmyLr74Yo0cOVILFy5UU1NT6OxviSYQCGjWrFltnrZ0fd+JsP9YoSENLe8/3l97LPn5doz3/mMl3l+Hn7+HYsnPt2O89x8rNOy6/Ud8woPf//73Gjt2bJvLJ0+erOXLl0uSHn30UT388MPauXOn8vPz9cgjj6iwsDAmCwYAAACAzojqbG8AAAAAYEVMX/MDAAAAAImK4QcAAACALzD8AAAAAPAFhh8AAAAAvuCb4eeBBx7QJZdcorS0tGP+9d3t27fr2muvVVpamgYMGKC7775bhw4dCtvm97//vS666CIFAgENHTo0dIa7zggGg8rJyVHPnj1VWFiotWvXdvq6jli9erXGjRun7OxsJSUlqaqqKuzjnudp5syZOu2009SrVy8VFRVp69atYdvs3btXN910k9LT09WnTx/9x3/8hxobG6NeW7RoeJjlhlLideyKhpLbHROtocR9sTMSrSP3xcglWkOJ+2KkaHhYtzb0fGLmzJneggULvIqKCi8jI6PNxw8dOuSdf/75XlFRkffmm296zz//vJeZmenNmDEjtM3f/vY3Ly0tzauoqPBqa2u9RYsWeSkpKd6qVasiXs/TTz/tpaamekuXLvXeeustr6yszOvTp49XX18fzZfpPf/88969997r/eIXv/Akec8++2zYxx966CEvIyPDq6qq8jZs2OBdf/313llnneV99NFHoW2uueYaLy8vz/vzn//s/fGPf/SGDh3qfeUrX4lqXbFAw8MsN/S8xOrYVQ09z+2OidTQ87gvdlYideS+2DmJ1NDzuC92Bg0P686Gvhl+jli2bFm731zPP/+8l5yc7O3cuTN02f/8z/946enpXnNzs+d5nnfPPfd4w4YNC/u8SZMmecXFxRGvY+TIkd60adNC77e0tHjZ2dne3LlzI76uY/n0N1dra6s3cOBA7+GHHw5dtm/fPi8QCHg/+clPPM/zvNraWk+St27dutA2v/nNb7ykpCTvvffei9naokFD+w09LzE6dkdDz3O3YyI09Dzui9FKhI7cF6OTCA09j/tiNGjYfQ19c9jbiaxZs0YXXHCBsrKyQpcVFxeroaFBb731VmiboqKisM8rLi7WmjVrItrXwYMHtX79+rDrSk5OVlFRUcTXFYm6ujrt3LkzbL8ZGRkqLCwM7XfNmjXq06ePLr744tA2RUVFSk5O1muvvdZla4sFGtpvKHVfx3g1lNzvyH3RfkOJ+6ILHbkv0jASfmnI8PMvO3fuDPvGkhR6f+fOncfdpqGhQR999FGH97V79261tLS0e11H9tUVjlz38fa7c+dODRgwIOzjPXr00Kmnntqla4sFGtpvKHVfx3g1lNzvyH3RfkOJ+6ILHbkv0pCGbZkefqZPn66kpKTjvm3evDney8Rx0NANdLSPhm6go300tI+Gia1HvBcQjTvvvFNTpkw57jZDhgzp0HUNHDiwzdks6uvrQx878u+Ry47eJj09Xb169ergqqXMzEylpKS0e11H9tUVjlx3fX29TjvttLD95ufnh7bZtWtX2OcdOnRIe/fu7ZK10TAyidhQstkxXg2lxOxosaHEffHTLHbkvhjOYkOJ++LRaBiZ7m5o+pmf/v3767Of/exx31JTUzt0XaNGjdLGjRvDbtgXX3xR6enpys3NDW1TXV0d9nkvvviiRo0aFdG6U1NTNXz48LDram1tVXV1dcTXFYmzzjpLAwcODNtvQ0ODXnvttdB+R40apX379mn9+vWhbX73u9+ptbVVhYWFMV8TDSOTiA0lmx3j1VBKzI4WG0rcFz/NYkfui+EsNpS4Lx6NhpHp9obRna/Bjnfeecd78803vdmzZ3u9e/f23nzzTe/NN9/0Dhw44HneJ6cSvPrqq72amhpv1apVXv/+/ds9leDdd9/tbdq0yQsGg1GdSjAQCHjLly/3amtrvdtuu83r06dP2Nk8OuPAgQOhr02St2DBAu/NN9/03nnnHc/zDp9KsE+fPt5zzz3n/eUvf/G++MUvtnsqwYKCAu+1117zXnnlFe/ss89OiNNB0tB+Q89LrI5d1dDz3O6YSA09j/tiZyVSR+6LnZNIDT2P+2Jn0LD7G/pm+Jk8ebInqc3byy+/HNpm27ZtXklJiderVy8vMzPTu/POO72PP/447HpefvllLz8/30tNTfWGDBniLVu2rNNrWrRokXfGGWd4qamp3siRI70///nPnb6uo9fX3tc5efJkz/MOn07wu9/9rpeVleUFAgHvyiuv9LZs2RJ2HXv27PG+8pWveL179/bS09O90tLS0J0wnmg42fM82w09L/E6dkXDI+tztWOiNfQ87oudkWgduS9GLtEaeh73xUjRcLLned3bMMnzPC+y54oAAAAAwB7Tr/kBAAAAgI5i+AEAAADgCww/AAAAAHyB4QcAAACALzD8AAAAAPAFhh8AAAAAvsDwAwAAAMAXGH4AAAAA+ALDDwAAAABfYPgBAAAA4AsMPwAAAAB84f8BVn4/pAMK8+kAAAAASUVORK5CYII=","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAz4AAAHeCAYAAABaEN5zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt5ElEQVR4nO3df5CU9X0H8M+BcojKiYIIBDwx8cc5RSweJzG06pAyaEnEtEMyiQFMSKJHbQbbBseO2CQVkyiScbYSkxhoaBtjoiYticmIdtIYGn4YTQ3ilEQtVUERBUE8wt3TP1I2HBxwP/Zu9/nu6zVzA/vsc8/z3ed937198+w+1GRZlgUAAEDC+pV7AAAAAL1N8QEAAJKn+AAAAMlTfAAAgOQpPgAAQPIUHwAAIHmKDwAAkDzFBwAASJ7iAwAAJE/xASBJzz//fNTU1MSyZcvKPRQAKoDiAwA9cOutt8ZDDz3Upe/5+te/Hueee24MHDgw3vWud8Vdd93VO4MDoEjxAYAe6Grx+cpXvhIf//jH47zzzou77rorJk2aFNdff3184Qtf6L1BAhDHlHsAAFSHtra22Lt3bwwcOLDcQymbPXv2xE033RRXXHFFfOc734mIiLlz50ZbW1t87nOfi0984hMxZMiQMo8SIE3O+ADkwGuvvRZXX311DB48OE466aSYNWtWPPXUU4d8hmX27NlxwgknxIsvvhhXXnllnHDCCTFs2LD4q7/6q2htbS2ut//zL7fffnvcc889ceaZZ0ZtbW00NjbG2rVrSzLmmpqamDdvXvzTP/1TnHfeeVFbWxsPP/xwRES8+OKLcc0118Tw4cOjtrY2zjvvvLj33nvbff/evXvj5ptvjgkTJkRdXV0cf/zxMXny5HjssccO2dcbb7wRs2fPjrq6uuLxeeONNzoc16OPPhqTJ0+O448/Pk466aR4//vfH88880y7dWbPnh319fWHfO8tt9wSNTU17R7j7t27Y/ny5VFTUxM1NTUxe/bswx6Txx57LF577bW47rrr2i1vbm6O3bt3x8qVKw/7vQD0jDM+ABWura0tpk+fHmvWrIlrr702zjnnnPje974Xs2bN6nD91tbWmDp1ajQ1NcXtt98ejzzySNxxxx1x5plnxrXXXttu3X/+53+ON998Mz75yU9GTU1NfPGLX4yrrroqfvOb38Sxxx7b47E/+uij8e1vfzvmzZsXQ4cOjfr6+ti6dWtcdNFFxWI0bNiw+OEPfxgf+9jHYufOnfHpT386IiJ27twZX/va1+JDH/pQzJ07N9588834+te/HlOnTo01a9bE+PHjIyIiy7J4//vfHz/96U/jU5/6VJx77rnx4IMPdnh8HnnkkZg2bVqMHTs2brnlltizZ0/cddddcfHFF8cTTzzRYdk5km9+85vx8Y9/PCZOnBif+MQnIiLizDPPPOz6v/jFLyIi4sILL2y3fMKECdGvX7/4xS9+ER/5yEe6NAYAOikDoKJ997vfzSIiW7JkSXFZa2trdtlll2URkX3jG98oLp81a1YWEdlnP/vZdtu44IILsgkTJhRvP/fcc1lEZKecckq2ffv24vLvfe97WURk//qv/9rjcUdE1q9fv+xXv/pVu+Uf+9jHshEjRmTbtm1rt/yDH/xgVldXl7311ltZlmXZvn37spaWlnbrvP7669nw4cOza665prjsoYceyiIi++IXv1hctm/fvmzy5MmHHJ/x48dnp556avbaa68Vlz311FNZv379so9+9KPFZbNmzcpOP/30Qx7TwoULs4N/dR5//PHZrFmzjnww/l9zc3PWv3//Du8bNmxY9sEPfrBT2wGg67zVDaDCPfzww3HsscfG3Llzi8v69esXzc3Nh/2eT33qU+1uT548OX7zm98cst7MmTPbfaZk8uTJEREdrtsdf/zHfxwNDQ3F21mWxXe/+92YPn16ZFkW27ZtK35NnTo1duzYEU888URERPTv3z8GDBgQEb8767V9+/bYt29fXHjhhcV1IiJ+8IMfxDHHHNPubFb//v3jL/7iL9qN5eWXX44nn3wyZs+eHSeffHJx+bhx4+K9731v/OAHPyjJYz6SPXv2FB/TwQYOHBh79uzp9TEAVCtvdQOocC+88EKMGDEiBg0a1G75O9/5zg7XHzhwYAwbNqzdsiFDhsTrr79+yLpjxow5ZL2I6HDd7jjjjDPa3X711VfjjTfeiHvuuSfuueeeDr/nlVdeKf59+fLlcccdd8TGjRvjt7/9bYfb3X98TjjhhHbbOfvss9vdfuGFFzpcHhFx7rnnxo9+9KPYvXt3HH/88Z18dF133HHHxd69ezu87+23347jjjuu1/YNUO0UH4DE9O/fv8frZllWkrEc/EK+ra0tIiI+8pGPHPYzSuPGjYuIiBUrVsTs2bPjyiuvjL/+67+OU089Nfr37x+LFi2KX//61yUZ3+EceAGDAx14gYjuGDFiRLS2tsYrr7wSp556anH53r1747XXXouRI0f2aPsAHJ7iA1DhTj/99HjsscfirbfeanfWZ9OmTWUcVfcMGzYsTjzxxGhtbY0pU6Yccd3vfOc7MXbs2HjggQfaFZGFCxe2W+/000+PVatWxa5du9qd9Xn22WcPWa+j5RERGzdujKFDhxbP9gwZMqTDq8LtP2t0oMOVpI7svyDDunXr4vLLLy8uX7duXbS1tRXvB6D0fMYHoMJNnTo1fvvb38ZXv/rV4rK2trYoFAp9sv8dO3bExo0bY8eOHT3eVv/+/eMDH/hAfPe7342nn376kPtfffXVdutGtD/79POf/zxWr17d7nsuv/zy2LdvX9x9993FZa2trXHXXXe1W2/EiBExfvz4WL58ebtS8/TTT8ePf/zjdkXkzDPPjB07dsQvf/nL4rKXX345HnzwwUPGfPzxx3dYkt56663YuHFjbNu2rbjssssui5NPPrndWCMi7r777hg0aFBcccUVh2wHgNJwxgegwl155ZUxceLEuOGGG2LTpk1xzjnnxPe///3Yvn17RHTtjEN3PPjggzFnzpz4xje+ccT/o6azbrvttnjssceiqakp5s6dGw0NDbF9+/Z44okn4pFHHik+rj/90z+NBx54IGbMmBFXXHFFPPfcc7F06dJoaGiIXbt2Fbc3ffr0uPjii2PBggXx/PPPR0NDQzzwwAMdFrUvfelLMW3atJg0aVJ87GMfK17Ouq6uLm655Zbieh/84AfjM5/5TMyYMSOuv/76eOutt+Luu++Os846q92FFSJ+dynqRx55JBYvXhwjR46MM844I5qammLNmjVx6aWXxsKFC4vbPu644+Jzn/tcNDc3x5//+Z/H1KlT4z/+4z9ixYoV8fd///ftLroAQGk54wNQ4fr37x8rV66MmTNnxvLly+Omm26KkSNHFs/4DBw4sMwj7Jrhw4fHmjVrYs6cOfHAAw/EvHnz4stf/nJs3749vvCFLxTXmz17dtx6663x1FNPxfXXXx8/+tGPYsWKFYf8Hzj9+vWL73//+/HhD384VqxYETfddFOMGjUqli9ffsi+p0yZEg8//HCccsopcfPNN8ftt98eF110UTz++OPtLphwyimnxIMPPhiDBg2Kv/mbv4nly5fHokWLYvr06Ydsc/HixTFhwoT427/92/jQhz50yNmcg1133XVxzz33xH/9139Fc3NzPP7443HnnXfGjTfe2NVDCUAX1GSl+gQrAH3qoYceihkzZsRPf/rTuPjii8s9HACoaIoPQA7s2bOn3RXSWltb40/+5E9i3bp1sWXLFpdBBoCj8BkfgDJqbW1t94H+jpxwwgnx6U9/Ovbs2ROTJk2KlpaWeOCBB+JnP/tZ3HrrrX1eerZs2XLE+4877rioq6vro9EAQOc44wNQRs8///wh/8nnwRYuXBhnnXVW3HHHHbFp06Z4++23453vfGdce+21MW/evD4a6e8d7WIKs2bNimXLlvXNYACgkxQfgDJ6++2346c//ekR1xk7dmyMHTu2j0Z0dI888sgR7x85cmQ0NDT00WgAoHMUHwAAIHkuZw0AACRP8QEAAJKn+AAAAMlTfAAAgOQpPgAAQPIUHwAAIHmKDwAAkDzFBwAASJ7iAwAAJE/xAQAAkqf4AAAAyVN8AACA5Ck+AABA8hQfAAAgeYoPAACQPMUHAABInuIDAAAkT/EBAACSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMlTfAAAgOQdU+4BdFVbW1u89NJLceKJJ0ZNTU25h1NVsiyLN998M0aOHBn9+nW/M8uwfEqVYYQcy0WGaZBj/skwDXLMv65kmLvi89JLL8Xo0aPLPYyqtnnz5njHO97R7e+XYfn1NMMIOZabDNMgx/yTYRrkmH+dyTB3xefEE0+MiN89uMGDB5d5NNVl586dMXr06GIG3SXD8ilVhhFyLBcZpkGO+SfDNMgx/7qSYe6Kz/5Th4MHD/ZDVSY9PX0rw/IrxSl4OZaXDNMgx/yTYRrkmH+dydDFDQAAgOQpPgAAQPIUHwAAIHmKDwAAkLzcFJ9CoRANDQ3R2NhY7qHQTTJMgxzzT4ZpkGP+yTANcsyPmizLsnIPoit27twZdXV1sWPHDlfM6GOlOvYyLJ9SHns5locM0yDH/JNhGuSYf1057rk54wMAANBdig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMlTfAAAgOQpPgAAQPIUHwAAIHmKD1C16hesLPcQAIA+ovgAVU35AYDqoPgAAADJU3ygm5wpAADID8UHAABInuIDAAAkT/EBAACSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ik8Z+P9fAACgbyk+AABA8hQfAAAgeYoPAACQvNwUn0KhEA0NDdHY2FjuofRINX++J5UMq50c80+GaZBj/skwDXLMj5osy7JyD6Irdu7cGXV1dbFjx44YPHhwuYfTZfuLz/O3XVHmkXRdqY593jPcr37BytzlWMpjn0KOeZyPMkyDHPNPhmmQY/515bjn5owPAADQe1J/Z5Li04dS/2GqJvuzlCkAQD4oPgBAWflHJKAvKD4AAEDyFB8AACB5ig8AAFSpanqrqeIDVKVqeqIH6G2eU8kDxaePeEJIhywBAPJH8QGqjvIKANVH8SkTL7ygPMw9AGivWn43Kj4AQNlUywsuoPwUH6DqeeEFAOlTfAAAgOQpPgAAQPIUHwCgz3mLKZTfgfOwGuak4gMAACRP8QEAAJKn+AAAZVENb60BKofi0wc8sQPAkfldmU/1C1bKLjEp56n49LKUf3gAACAvFB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAoMtcwIm8UXygCzzJAwDkk+IDAAAkT/EBqoYzdgBQvRQf6CQvmgEA8kvx6UVeKANAe343AuWi+AAAAMlTfAAAgOQpPgAAUGWq8W2nig8AAD1WjS+kyRfFBwDoU14g558MySPFBwAASF6fF5/NmzfHJZdcEg0NDTFu3Li4//77+3oIAABAlTmmz3d4zDGxZMmSGD9+fGzZsiUmTJgQl19+eRx//PF9PRQAAKBK9HnxGTFiRIwYMSIiIk477bQYOnRobN++XfEBAAB6TZff6vaTn/wkpk+fHiNHjoyampp46KGHDlmnUChEfX19DBw4MJqammLNmjUdbmv9+vXR2toao0eP7vLAAQAAOqvLZ3x2794d559/flxzzTVx1VVXHXL/fffdF/Pnz4+lS5dGU1NTLFmyJKZOnRrPPvtsnHrqqcX1tm/fHh/96Efjq1/96hH319LSEi0tLcXbO3fu7OqQKTMZpkGO+SfDNMgx/2SYBjnmT5fP+EybNi0+//nPx4wZMzq8f/HixTF37tyYM2dONDQ0xNKlS2PQoEFx7733FtdpaWmJK6+8MhYsWBDvfve7j7i/RYsWRV1dXfHL2aH8kWEa5Jh/MkyDHPNPhmmQY/6U9Kpue/fujfXr18eUKVN+v4N+/WLKlCmxevXqiIjIsixmz54dl112WVx99dVH3eaNN94YO3bsKH5t3ry5lEOmD8gwDXLMPxmmQY75J8M0yDF/Snpxg23btkVra2sMHz683fLhw4fHxo0bIyLi8ccfj/vuuy/GjRtX/HzQN7/5zfiDP/iDDrdZW1sbtbW1pRwmfUyGaZBj/skwDXLMPxmmQY750+dXdXvPe94TbW1tfb1bAACgipX0rW5Dhw6N/v37x9atW9st37p1a5x22mml3BUAAECnlbT4DBgwICZMmBCrVq0qLmtra4tVq1bFpEmTSrmrile/YGW5hwAAAPy/Lr/VbdeuXbFp06bi7eeeey6efPLJOPnkk2PMmDExf/78mDVrVlx44YUxceLEWLJkSezevTvmzJlT0oEDdIV/jACA6tbl4rNu3bq49NJLi7fnz58fERGzZs2KZcuWxcyZM+PVV1+Nm2++ObZs2RLjx4+Phx9++JALHnRVoVCIQqEQra2tPdoO5SPDNMgx/2SYBjnmnwzTIMf8qMmyLCv3ILpi586dUVdXFzt27IjBgweXeziH1Zl/XX7+tiv6YCSlU6pjn5cMD3a4TPOUYymPfd5yPNqczEuO1ZxhSqo5xyPNxbzMw4jqzjAijd+JEdWdYzXOxZJ+xgcAAKASKT4AAEDyFB8AADrNxWLIK8UHAACqSLWWV8UHAABInuIDAAAkLzfFp1AoRENDQzQ2NpZ7KEdVracPjyZPGXJ4csw/GaZBjvmXxwy9xjlUHnOsVrkpPs3NzbFhw4ZYu3ZtuYdCN8kwDXLMPxmmQY75J8M0yDE/clN8AAAAukvxgU5wah8AIN8UHwAAIHmKDwBQEZxdB3qT4gMAACRP8QEAAJKXm+LjGun5J8M0yDH/ZJgGOeafDNMgx/zITfFxjfT8k2Ea5Jh/MkyDHPNPhmnIU47V/jm63BQfAACA7lJ8AACA5Ck+AABA8hQfAAAgeYpPGVX7B8zyQk4AQCqq+XWN4gMAACRP8QEA+kQ1/0szUH6KDwAAkLzcFB//K27+yTANcsw/GaZBjvknwzTIMT9yU3zy9L/i0jEZpkGO+SfDNOQtR29zO1TeMqRjcsyP3BQfgO7wYgsAiFB8AACAKqD4AAAAyVN8SszbagCgPb8bgUqg+ADJ86ILAFB8AACA5Ck+QLKc6QEoHc+p5J3iAwD0Ci+UgUqi+AAAAEWp/qNFbopPoVCIhoaGaGxsLPdQ6CYZpkGO+SfDNMgx/2SYBjnmR26KT3Nzc2zYsCHWrl1b7qHQTTJMgxzzT4ZpkGP+yTANcsyP3BQfgN6U6ml9AOB3FB8AACB5ig8AAEfkrDgpUHwAAIDkKT4AQK9xpqC6yJtKpvgAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4lNCLuEIAH4fApUpN8WnUChEQ0NDNDY2lnsodJMM0yDH/JNhGuSYfzJMgxzzIzfFp7m5OTZs2BBr164t91DoJhmmQY75J8M0yDH/ZJgGOebHMeUeAAAA0Hu8/fR3cnPGBwAAoLsUHwAAIHmKT4k4hZgmuQJQ7fwuJBWKDwAAkDzFBwAASJ7iAwAAJE/xAQAAkqf4AAAAyVN8SsDVTvJNfgAA6VN8AACA5Ck+cJD6BSudBQKA8K4I0qL4AAAAyVN8oIf8a1hlkQcA0BHFBwAASJ7iAwAAJE/xAQAAkpeb4lMoFKKhoSEaGxvLPZSSqqbPI1R6htWURU9Ueo4RsjyaPGTI0ckx/2SYBjnmR26KT3Nzc2zYsCHWrl1b7qHQTTJMgxzzT4ZpkGP+yTANcsyP3BSfcvMvyNVBzumQJQBwIMUHAABInuIDAJScs675JTtSpfgAAADJU3wAAIDkKT4AAEDyFB8AACB5ig9V62gf3vThToDO85wJVDrFBwAASJ7i0wP+dQvKyxyEymNeApVK8QEAAJKn+AAAAMlTfAAAOIS3Leab/A6l+AAAAMlTfA7DpY4hf8xLKA9zLx37s5QpKVJ8AACA5Ck+AABA8hQfIAnelgF9z7zLN/mlT8btKT4AAEDyFB8AACB5ik8POYWYT3IDKD3Prfkjs/TJ+PcUHwAAIHmKDwAAkLzcFJ9CoRANDQ3R2NjYq/vpzOlApwy7p68y7ApZdl2l5SjDrqu0DOkeOeafDNMgx/zITfFpbm6ODRs2xNq1a8s9FLpJhmmQY/7JMA1yzD8ZpkGO+ZGb4gMAANBdig8AAJA8xecI6hesbPf5AZ8lgLQdPOeBQ5kjafL8x8FS/HlQfAAAgOQpPgAAQPIUny5K8bQf5JG5CJXBXATyQvEBAACSp/gAAADJU3wAAIDkKT5UnY7ej+496gBQOn6vUokUHwAAIHmKDwAAkDzF5wCHOy3rdG3+9XaGfkbKy/EHgN/xO/HwFB8AACB5ig8AAJA8xQcAAEie4vP/vB+yOsgZoLJ5nu5dji/VTPEBAACSp/gAAADJU3wAAIDkKT4AAEDyFB+gYvkQLlQmczMt8qRaKD4AAEDyFB8AACB5ig8AAJA8xQcAAEie4tMBH/KDyrN/XpqfAD3nuTRt8u2Y4gMAACRP8QEAAJKn+AAAAMlTfAAAgOQpPkDu+NAmlIe5lwY5Uq0UHwAAIHmKDwAAkDzFBwAASJ7iAwAAJE/xqTA+cNh7+urYyrBn9h+/jo6jYwuVw3zMh/oFK4tfUO3KUnxmzJgRQ4YMiT/7sz8rx+4BAIAqU5bi85d/+Zfxj//4j+XYNQAAUIXKUnwuueSSOPHEE8uxawAAoAp1ufj85Cc/ienTp8fIkSOjpqYmHnrooUPWKRQKUV9fHwMHDoympqZYs2ZNKcYKAADQLcd09Rt2794d559/flxzzTVx1VVXHXL/fffdF/Pnz4+lS5dGU1NTLFmyJKZOnRrPPvtsnHrqqV0eYEtLS7S0tBRv79y5s8vboLxkmAY55p8M0yDH/JNhGuSYP10+4zNt2rT4/Oc/HzNmzOjw/sWLF8fcuXNjzpw50dDQEEuXLo1BgwbFvffe260BLlq0KOrq6opfo0eP7tZ2jqTcVzpJ/WorfZFhR8p9TMu9/1IrV46UjgzTUK3PqSlJPcNq+VlJPccUlfQzPnv37o3169fHlClTfr+Dfv1iypQpsXr16m5t88Ybb4wdO3YUvzZv3lyq4dJHZJgGOeafDNMgx/yTYRrkmD9dfqvbkWzbti1aW1tj+PDh7ZYPHz48Nm7cWLw9ZcqUeOqpp2L37t3xjne8I+6///6YNGlSh9usra2N2traUg6TPibDNMgx/2SYBjnmnwzTIMf8KWnx6axHHnmkHLsFAACqVEnf6jZ06NDo379/bN26td3yrVu3xmmnnVbKXQEAAHRaSYvPgAEDYsKECbFq1arisra2tli1atVh38oGAADQ27r8Vrddu3bFpk2birefe+65ePLJJ+Pkk0+OMWPGxPz582PWrFlx4YUXxsSJE2PJkiWxe/fumDNnTkkHDgAA0FldPuOzbt26uOCCC+KCCy6IiIj58+fHBRdcEDfffHNERMycOTNuv/32uPnmm2P8+PHx5JNPxsMPP3zIBQ+6qlAoRENDQzQ2NvZoO5SPDNPQGzke6dKc5bhsZ+qXCjUX05B6jqnPw4j0M6wW1ZBjKvOxy8XnkksuiSzLDvlatmxZcZ158+bFCy+8EC0tLfHzn/88mpqaejzQ5ubm2LBhQ6xdu7bH26I8ZJgGOeafDNMgx/yTYRrkmB8l/YwPAABAJVJ8AACA5Ck+AABA8hQfAAAgeYoPAACQvNwUn2q4VGDqypVhX16CMZXLPR5JOXKshuPalzyfpqEvcjT3ele1zMXUf45Sf31z4H7ynmVuio9LBeafDNMgx/yTYRrkmH8yTIMc8yM3xQcAAKC7FB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMk7ptwD6KxCoRCFQiFaW1t7tJ36BSvj+duuKP69klTaeEqtVBl2RerHtBzKkSOlJcM09GWOff1cWi3P3eZiGsqdY2/Ol9TmYm7O+PjPofJPhmmQY/7JMA1yzD8ZpkGO+ZGb4gMAANBdig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMlTfAAAgOTlpvgUCoVoaGiIxsbGcg+Fbko9w9T+k6/DKXWOHR23ajmW5ZL6XKwW1ZDj/ueCVJ8TUs8w1dwOVo4cq+XYllpuio//HCr/ZJgGOeafDNMgx/yTYRrkmB+5KT4AAADdpfgAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMnLTfEpFArR0NAQjY2N5R5K7tQvWFnuIURE32VYv2Bl2R9zufffm6ppLqaaYzVlmLLezPHA59FU50ElMBfTUC05pvBckJvi09zcHBs2bIi1a9eWeyh0kwzTIMf8k2Ea5Jh/MkyDHPMjN8UHAACguxQfAAAgeYoPAACQPMUHAABInuIDAAAkT/EBAACSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEhebopPoVCIhoaGaGxs7PG26hesLMGIek/9gpUVP8buKGWGlE9v5lhJP/e9OZZyP05zMQ3VkuOB86Xcc6fUeiPDvB+vPI65L+fiwcen3Mer3PvvqtwUn+bm5tiwYUOsXbu23EOhm2SYBjnmnwzTIMf8k2Ea5JgfuSk+AAAA3aX4AAAAyVN8AACA5Ck+AABA8hQfAAAgeYoPAACQPMUHAABInuIDAAAkT/EBAACSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4gMAACQvN8WnUChEQ0NDNDY2dun76hesPOrf86Sjcff0sfTVsehuhp1VyZkebmz1C1ZW9Lg70ts5VqL9GR0tq7xkWY0ZpqiUOebt92N3xluJj6vUc7ESH2NvvG6pNH3x+qYSj1kljuloclN8mpubY8OGDbF27dpyD4VukmEa5Jh/MkyDHPNPhmmQY37kpvgAAAB0l+IDAAAkT/EBAACSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMlTfAAAgOQpPgAAQPIUHwAAIHmKDwAAkDzFBwAASJ7iAwAAJE/xAQAAkqf4AAAAyVN8AACA5Ck+AABA8hQfAAAgeYoPAACQvNwUn0KhEA0NDdHY2HjUdesXrIz6BSsPezsvDjfmAx9PR+sc/NgrRVcy7IyOHmclPd6II4+nu/d1ZZ3eUIocO5qTlZbdfgf/bB3459HGXC1zkfKo1hwr9fm+O0qV4dFeC1SKzj5nVuLYj6S35mIl/5482tg6ei1eCXJTfJqbm2PDhg2xdu3acg+FbpJhGuSYfzJMgxzzT4ZpkGN+5Kb4AAAAdJfiAwAAJE/xAQAAkqf4AAAAyVN8AACA5Ck+AABA8hQfAAAgeYoPAACQPMUHAABInuIDAAAkT/EBAACSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMlTfAAAgOQpPgAAQPIUHwAAIHmKDwAAkDzFBwAASJ7iAwAAJE/xAQAAkqf4AAAAyVN8AACA5Ck+AABA8hQfAAAgeYoPAACQPMUHAABInuIDAAAkT/EBAACSp/gAAADJK0vx+bd/+7c4++yz413veld87WtfK8cQAACAKnJMX+9w3759MX/+/Hjssceirq4uJkyYEDNmzIhTTjmlr4cCAABUiT4/47NmzZo477zzYtSoUXHCCSfEtGnT4sc//nFfDwMAAKgiXS4+P/nJT2L69OkxcuTIqKmpiYceeuiQdQqFQtTX18fAgQOjqakp1qxZU7zvpZdeilGjRhVvjxo1Kl588cXujR4AAKATulx8du/eHeeff34UCoUO77/vvvti/vz5sXDhwnjiiSfi/PPPj6lTp8Yrr7zS48ECAAB0R5c/4zNt2rSYNm3aYe9fvHhxzJ07N+bMmRMREUuXLo2VK1fGvffeGwsWLIiRI0e2O8Pz4osvxsSJEw+7vZaWlmhpaSne3rlzZ1eHTJnJMA1yzD8ZpkGO+SfDNMgxf0r6GZ+9e/fG+vXrY8qUKb/fQb9+MWXKlFi9enVEREycODGefvrpePHFF2PXrl3xwx/+MKZOnXrYbS5atCjq6uqKX6NHjz5knfoFK4/697yqX7Cy+NWZ9TqzvQP/PNp6pdCZDLurs4+7Ehx47I805sOtd+DtcjzmruR4uPEdvDwv2R2so1wOzu1ox6Acz1u9ORfpO6XOsZzPK13R2d9bHT2HdnaO9dUx6O25WIlZdpTP/j87es480vqVopQ5dvb3ZiXrKMuu/D7si8da0uKzbdu2aG1tjeHDh7dbPnz48NiyZUtERBxzzDFxxx13xKWXXhrjx4+PG2644YhXdLvxxhtjx44dxa/NmzeXcsj0ARmmQY75J8M0yDH/ZJgGOeZPn1/OOiLife97X7zvfe/r1Lq1tbVRW1vbyyOiN8kwDXLMPxmmQY75J8M0yDF/SnrGZ+jQodG/f//YunVru+Vbt26N0047rZS7AgAA6LSSFp8BAwbEhAkTYtWqVcVlbW1tsWrVqpg0aVIpdwUAANBpXX6r265du2LTpk3F288991w8+eSTcfLJJ8eYMWNi/vz5MWvWrLjwwgtj4sSJsWTJkti9e3fxKm8AAAB9rcvFZ926dXHppZcWb8+fPz8iImbNmhXLli2LmTNnxquvvho333xzbNmyJcaPHx8PP/zwIRc86KpCoRCFQiFaW1t7tB3KR4ZpkGP+yTANcsw/GaZBjvnR5be6XXLJJZFl2SFfy5YtK64zb968eOGFF6KlpSV+/vOfR1NTU48H2tzcHBs2bIi1a9f2eFuUhwzTIMf8k2Ea5Jh/MkyDHPOjpJ/xAQAAqESKDwAAkDzFBwAASJ7iAwAAJE/xAQAAkqf4AAAAyctN8SkUCtHQ0BCNjY3lHgrdJMM0yDH/ZJgGOeafDNMgx/zITfFxjfT8k2Ea5Jh/MkyDHPNPhmmQY34cU+4BdFWWZRERsXPnzuKytpa3irfbWt4qy7j6ws6dO9s9voNvH7js4ONx4O2O1jnweB5u2f7b+zPoro4y7I68ZH1gTh1ltn/5fh1leuDyg7fX1bFE9DzDA7fR0Rg6+vk5cHlesiuFjube4e47+O9H2l5vZ0jvqqQcj/Z7pZId+Pusoz8PXOfg9TtytPl38L4jKifDvGUXcfSftyPlW8oxRJQ/x8O9FqtEnXk9erjvO1Cpsu1KhjVZKZLuQ//7v/8bo0ePLvcwqtrmzZvjHe94R7e/X4bl19MMI+RYbjJMgxzzT4ZpkGP+dSbD3BWftra2eOmll+LEE0+Mmpqakmxz586dMXr06Ni8eXMMHjy4JNus5P12d99ZlsWbb74ZI0eOjH79uv8uyZQyzNu+S5VhROlzzNNxLOe+KznDiHwdy3Luu5JzzNNxLOe+KznDiHwdy3Lut5JzrMYMu7PvrmSYu7e69evXr8eN/HAGDx7c5+GWc7/d2XddXV2P95lihnnadykyjOi9HPNyHMu570rPMCI/x7Kc+670HPNyHMu570rPMCI/x7Kc+630HKsxw67uu7MZ5ubiBgAAAN2l+AAAAMlTfCKitrY2Fi5cGLW1tVWx33LvuzdU67FMKcdqPY4pZRhRvccypRyr9TimlGFEdR5LGdr30eTu4gYAAABd5YwPAACQPMUHAABInuIDAAAkT/EBAACSp/gAAADJq+riU19fHzU1Ne2+brvttnbr/PKXv4zJkyfHwIEDY/To0fHFL36xZPsvFApRX18fAwcOjKamplizZk3Jtr3fLbfccshjPOecc4r3v/3229Hc3BynnHJKnHDCCfGBD3wgtm7dWvJx9KZy5ijD0jAX5dhTMiyN1OdiNWQYYS6mkKMMeynDrIqdfvrp2Wc/+9ns5ZdfLn7t2rWreP+OHTuy4cOHZx/+8Iezp59+OvuXf/mX7Ljjjsu+8pWv9Hjf3/rWt7IBAwZk9957b/arX/0qmzt3bnbSSSdlW7du7fG2D7Rw4cLsvPPOa/cYX3311eL9n/rUp7LRo0dnq1atytatW5dddNFF2bvf/e6SjqG3lStHGZaOuSjHnpBh6aQ+F6shwywzF1PIUYa9k2HVF58777zzsPf/wz/8QzZkyJCspaWluOwzn/lMdvbZZ/d43xMnTsyam5uLt1tbW7ORI0dmixYt6vG2D7Rw4cLs/PPP7/C+N954Izv22GOz+++/v7jsmWeeySIiW716dUnH0ZvKlaMMS8dclGNPyLB0Up+L1ZBhlpmLKeQow97JsKrf6hYRcdttt8Upp5wSF1xwQXzpS1+Kffv2Fe9bvXp1/NEf/VEMGDCguGzq1Knx7LPPxuuvv97tfe7duzfWr18fU6ZMKS7r169fTJkyJVavXt3t7R7Of//3f8fIkSNj7Nix8eEPfzj+53/+JyIi1q9fH7/97W/bjeOcc86JMWPG9Mo4elNf5yjD0jMX5dgdMiy91OdiNWQYYS6mkKMMS5/hMT367py7/vrr4w//8A/j5JNPjp/97Gdx4403xssvvxyLFy+OiIgtW7bEGWec0e57hg8fXrxvyJAh3drvtm3borW1tbitA7e9cePGbm3zcJqammLZsmVx9tlnx8svvxx/93d/F5MnT46nn346tmzZEgMGDIiTTjrpkHFs2bKlpOPoTeXIUYalZS7K0VysDKnPxWrIMMJcTCFHGfZOhskVnwULFsQXvvCFI67zzDPPxDnnnBPz588vLhs3blwMGDAgPvnJT8aiRYuitra2t4faJ6ZNm1b8+7hx46KpqSlOP/30+Pa3vx3HHXdcGUd2ZHL8PRnmP8MIOaaQowxlWE5y/L285ijD3ytXhskVnxtuuCFmz559xHXGjh3b4fKmpqbYt29fPP/883H22WfHaaeddsgVJPbfPu2007o9xqFDh0b//v073HZPttsZJ510Upx11lmxadOmeO973xt79+6NN954o12r7otxHE2l5yjDo6v0DCPk2BmVnqMMj67SM4woX455yTCi8nM0F49OhofXZxn26BNCiVmxYkXWr1+/bPv27VmW/f6DY3v37i2uc+ONN5bsQ5zz5s0r3m5tbc1GjRpV8g+PHezNN9/MhgwZkn35y18ufnjsO9/5TvH+jRs35u4DgAfrqxxl2HvMRTl2hQx7T+pzsRoyzDJzMYUcZViaDKu2+PzsZz/L7rzzzuzJJ5/Mfv3rX2crVqzIhg0bln30ox8trvPGG29kw4cPz66++urs6aefzr71rW9lgwYNKtllO2tra7Nly5ZlGzZsyD7xiU9kJ510UrZly5Yeb/tAN9xwQ/bv//7v2XPPPZc9/vjj2ZQpU7KhQ4dmr7zySpZlv7tc4JgxY7JHH300W7duXTZp0qRs0qRJJR1DbypnjjIsDXNRjuZiZaiGuZh6hllmLmZZ/nOUYe9lWLXFZ/369VlTU1NWV1eXDRw4MDv33HOzW2+9NXv77bfbrffUU09l73nPe7La2tps1KhR2W233VayMdx1113ZmDFjsgEDBmQTJ07M/vM//7Nk295v5syZ2YgRI7IBAwZko0aNymbOnJlt2rSpeP+ePXuy6667LhsyZEg2aNCgbMaMGdnLL79c8nH0lnLnKMOeK3eGWSbHUih3jjLsuXJnmGW9n2PqGWZZ+XM0F3tOhr2XYU2WZVnP3iwHAABQ2ar+//EBAADSp/gAAADJU3wAAIDkKT4AAEDyFB8AACB5ig8AAJA8xQcAAEie4gMAACRP8QEAAJKn+AAAAMlTfAAAgOT9HwkMl5wxeY6CAAAAAElFTkSuQmCC","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 7 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["with torch.no_grad():\n","    activations = compute_activations_across_models_v1(\n","        args, \n","        models_list,\n","        train_dataloader,\n","        args.act_num_samples,\n","        mode='raw',\n","        layer_names=layer_names\n","    )\n","\n","plt.close('all')\n","for layer_names, acts in zip(\n","    zip(*[activations[i].keys() for i in range(len(activations))]),\n","    zip(*[activations[i].values() for i in range(len(activations))])\n","):\n","    fig, axes = plt.subplots(1, len(acts), figsize=(10, 5), sharey=True, sharex=True)\n","    fig.suptitle(layer_names[0])\n","    print(layer_names[0], [a.shape for a in acts])\n","    print(layer_names[0], [a.min().item() for a in acts])\n","    print(layer_names[0], [a.max().item() for a in acts])\n","    a_std_rel = []\n","    for i, a in enumerate(acts):\n","        a_flattened = a.flatten().cpu().numpy()\n","        if i == 0:\n","            a_std_rel.append(1)\n","        else:\n","            a_std_rel.append(a_flattened.std() / a_std_rel[0])\n","        axes[i].hist(a_flattened, bins=100)\n","        axes[i].set_yscale('log')\n","    print(layer_names[0], a_std_rel)\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["_gnn._conv_layers.0.nn.0.weight 1.0000128 0.707125\n","_gnn._conv_layers.0.nn.2.weight 1.0000384 0.5000384\n","_gnn._conv_layers.1.nn.0.weight 1.0000591 0.5000592\n","_gnn._conv_layers.1.nn.2.weight 1.0000592 0.5000592\n","_gnn._conv_layers.2.nn.0.weight 1.0000592 0.5000592\n","_gnn._conv_layers.2.nn.2.weight 1.0000592 0.5000592\n","_gnn._conv_layers.3.nn.0.weight 1.0000592 0.5000591\n","_gnn._conv_layers.3.nn.2.weight 1.0000592 0.5000592\n","_gnn._post_processing.0.weight 1.0000587 0.71088207\n","_gnn._post_processing.2.weight 1.0000592 1.0000591\n","_gnn._readout.0.weight 1.0000385 1.0000385\n","_tasks.0._affine.weight 1.0000128 1.0000128\n"]}],"source":["for idx, (\n","    (layer0_name, fc_layer0_weight), \n","    (layer1_name, fc_layer1_weight),\n","    (layer2_name, fc_layer2_weight),\n",") in enumerate(zip(\n","    models['small_seed_0_epochs_10'].named_parameters(), \n","    models['small_seed_0_epochs_10_mapped'].named_parameters(),\n","    models['large_seed_0_epochs_10_mapped'].named_parameters(),\n",")):\n","    with torch.no_grad():\n","        s1 = (((fc_layer0_weight.abs() ** 2).sum() ** 0.5) / ((fc_layer1_weight.abs() ** 2).sum() ** 0.5)).cpu().numpy()\n","        s2 = (((fc_layer0_weight.abs() ** 2).sum() ** 0.5) / ((fc_layer2_weight.abs() ** 2).sum() ** 0.5)).cpu().numpy()\n","        print(layer0_name, s1, s2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_dataloader = make_dataloader(db = config_small['inference_database_path'],\n","    selection = None, # Entire database\n","    pulsemaps = config_small['pulsemap'],\n","    features = features,\n","    truth = truth,\n","    batch_size = config_small['batch_size'],\n","    num_workers = config_small['num_workers'],\n","    shuffle = False,\n","    labels = {'direction': Direction()},\n","    index_column = config_small['index_column'],\n","    truth_table = config_small['truth_table'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [300], which does not match the required output shape [100, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [55314], which does not match the required output shape [9219, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [51066], which does not match the required output shape [8511, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [63270], which does not match the required output shape [10545, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [50394], which does not match the required output shape [8399, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [55398], which does not match the required output shape [9233, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [52710], which does not match the required output shape [8785, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [47322], which does not match the required output shape [7887, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [54636], which does not match the required output shape [9106, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [62112], which does not match the required output shape [10352, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [90546], which does not match the required output shape [15091, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [93186], which does not match the required output shape [15531, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [91002], which does not match the required output shape [15167, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [74052], which does not match the required output shape [12342, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [48570], which does not match the required output shape [8095, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [189384], which does not match the required output shape [31564, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [51222], which does not match the required output shape [8537, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [328254], which does not match the required output shape [54709, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [46440], which does not match the required output shape [7740, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [46086], which does not match the required output shape [7681, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [47052], which does not match the required output shape [7842, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [51090], which does not match the required output shape [8515, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [122268], which does not match the required output shape [20378, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [55122], which does not match the required output shape [9187, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [72006], which does not match the required output shape [12001, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [50094], which does not match the required output shape [8349, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [80286], which does not match the required output shape [13381, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [129570], which does not match the required output shape [21595, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60972], which does not match the required output shape [10162, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [321210], which does not match the required output shape [53535, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [168372], which does not match the required output shape [28062, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [53298], which does not match the required output shape [8883, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [440544], which does not match the required output shape [73424, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [50118], which does not match the required output shape [8353, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [59538], which does not match the required output shape [9923, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [424974], which does not match the required output shape [70829, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [152244], which does not match the required output shape [25374, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [140394], which does not match the required output shape [23399, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [57186], which does not match the required output shape [9531, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [56088], which does not match the required output shape [9348, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [47934], which does not match the required output shape [7989, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [70176], which does not match the required output shape [11696, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [43800], which does not match the required output shape [7300, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [115308], which does not match the required output shape [19218, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [144450], which does not match the required output shape [24075, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [55266], which does not match the required output shape [9211, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [49410], which does not match the required output shape [8235, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [108774], which does not match the required output shape [18129, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [61740], which does not match the required output shape [10290, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [88908], which does not match the required output shape [14818, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [326286], which does not match the required output shape [54381, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [660432], which does not match the required output shape [110072, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [45744], which does not match the required output shape [7624, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [37728], which does not match the required output shape [6288, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [78774], which does not match the required output shape [13129, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [54396], which does not match the required output shape [9066, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [141906], which does not match the required output shape [23651, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [43914], which does not match the required output shape [7319, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [55674], which does not match the required output shape [9279, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [60324], which does not match the required output shape [10054, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [82818], which does not match the required output shape [13803, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [46032], which does not match the required output shape [7672, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [49134], which does not match the required output shape [8189, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [186054], which does not match the required output shape [31009, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [187842], which does not match the required output shape [31307, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [51480], which does not match the required output shape [8580, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [125334], which does not match the required output shape [20889, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [67248], which does not match the required output shape [11208, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [71490], which does not match the required output shape [11915, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [96420], which does not match the required output shape [16070, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [225480], which does not match the required output shape [37580, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [102186], which does not match the required output shape [17031, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [50718], which does not match the required output shape [8453, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [162528], which does not match the required output shape [27088, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [56892], which does not match the required output shape [9482, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [75498], which does not match the required output shape [12583, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [45510], which does not match the required output shape [7585, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [44994], which does not match the required output shape [7499, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [114570], which does not match the required output shape [19095, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [53706], which does not match the required output shape [8951, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [50244], which does not match the required output shape [8374, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [186594], which does not match the required output shape [31099, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [112476], which does not match the required output shape [18746, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [80736], which does not match the required output shape [13456, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [146382], which does not match the required output shape [24397, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [84324], which does not match the required output shape [14054, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [64140], which does not match the required output shape [10690, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [62202], which does not match the required output shape [10367, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [56814], which does not match the required output shape [9469, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [98598], which does not match the required output shape [16433, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [67974], which does not match the required output shape [11329, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [133098], which does not match the required output shape [22183, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [312384], which does not match the required output shape [52064, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [182352], which does not match the required output shape [30392, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [159120], which does not match the required output shape [26520, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [64914], which does not match the required output shape [10819, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [59166], which does not match the required output shape [9861, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [63432], which does not match the required output shape [10572, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [114690], which does not match the required output shape [19115, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [179190], which does not match the required output shape [29865, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [51594], which does not match the required output shape [8599, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [63672], which does not match the required output shape [10612, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [67314], which does not match the required output shape [11219, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [49542], which does not match the required output shape [8257, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [38394], which does not match the required output shape [6399, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [98814], which does not match the required output shape [16469, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [53250], which does not match the required output shape [8875, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [112710], which does not match the required output shape [18785, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n","/root/miniconda3/envs/graphnet/lib/python3.8/site-packages/torch_geometric/data/collate.py:150: UserWarning: An output with one or more elements was resized since it had shape [54456], which does not match the required output shape [9076, 6]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n","  value = torch.cat(values, dim=cat_dim or 0, out=out)\n"]}],"source":["# from torchviz import make_dot\n","\n","# x = next(iter(test_dataloader)).cpu()\n","# y = model_small_seed_0.cpu()(x)\n","\n","# make_dot(sum(y) / len(y), params=dict(list(model_small_seed_0.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resilts = defaultdict(list)\n","for i, batch in enumerate(test_dataloader):\n","    with torch.no_grad():\n","        for model_name, model in models.items():\n","            resilts[model_name].append(model(batch.cuda()))\n","    if i > 100:\n","        break\n","print(*[model_name for model_name in resilts.keys()])\n","for x in zip(*[resilts[model_name] for model_name in resilts.keys()]):\n","    print([(np.abs(y[0].cpu().numpy()) ** 2).sum() ** 0.5 for y in x])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7094946027372634\n","1.1294778917797688\n","0.8170302896232713\n","1.12797236552434\n","0.7495856745052625\n","0.7680559813707611\n","1.0511098717558993\n","0.6142274092344437\n","0.6901523543019394\n","0.7931526355240274\n","0.6918536896154366\n","0.7539773682243746\n","0.8917250173915617\n","0.7814085363187775\n","0.8163306509430815\n","0.49320500495946484\n","0.790682938110545\n","1.0245463460473905\n","0.6544302619247042\n","0.9033840775046984\n","0.5774004538778444\n","0.49570851081282497\n","0.7543168595705708\n","0.7127959776126829\n","0.7460334410998734\n","0.7143117244168601\n","1.072057930196843\n","1.1110300535306703\n","0.7843814006587404\n","0.8110464786773445\n","0.7830589915889938\n","0.8037546905918469\n","0.8796158952334239\n","0.5668433721979299\n","0.7571791154009802\n","0.9234565526013073\n","0.9206133573149855\n","0.9524628474198289\n","0.6287037652309543\n","0.7777570483383095\n","0.8898851576672945\n","0.7964136907483438\n","0.6947727618333756\n","0.8934560018888705\n","0.6485834699210223\n","0.532572838177545\n","0.7390420598239109\n","0.7383250415599085\n","0.9222881751542106\n","1.0009759772078701\n","0.637504806442919\n","0.9284484445734775\n","0.8477550936157527\n","0.7696045077876567\n","0.7581410312186564\n","0.7824674648326294\n","0.7129158817402075\n","0.8208657140217855\n","0.6936401905968599\n","0.8483388585742176\n","0.9249480176875889\n","0.8467701996917114\n","0.742079454202063\n","0.8108016510567067\n","0.5649669765058983\n","0.5394528687040736\n","0.6605936274364466\n","0.8417585369586317\n","0.6203205217431477\n","0.7869497268636627\n","0.6099044890092048\n","0.7014739950421275\n","0.7439377020042356\n","0.6321788077956134\n","0.7123350639406647\n","0.7877495007713549\n","0.7976970492475488\n","0.5990541606797102\n","0.8829272589355818\n","0.7422789910935386\n","0.7768146069841044\n","0.5552854831664865\n","0.6374955059168563\n","1.1003652191470992\n","0.8627515908518624\n","0.6917389821445191\n","0.7656477980720728\n","0.8937336699122513\n","0.811686690998988\n","0.775471401965756\n","0.4680637505887512\n","0.788702813146393\n","0.6365063438266767\n","0.7570985634238576\n","0.8014631365425706\n","0.9081259362536453\n","0.8467884742180709\n","0.5040479345299623\n","0.8497978330673887\n","0.6401626592295742\n","0.703653091644474\n","0.8068286775700731\n"]}],"source":["vs = []\n","for a, b, c in zip(models['small_seed_0_epochs_10'], models['small_seed_1_epochs_10'], models['small_seed_0_epochs_10_mapped']):\n","    print(\n","        v := ((np.abs(c[0].cpu().numpy()) ** 2).sum() ** 0.5) / ((\n","            ((np.abs(a[0].cpu().numpy()) ** 2).sum() ** 0.5) +\n","            ((np.abs(b[0].cpu().numpy()) ** 2).sum() ** 0.5)\n","        ) / 2)\n","    )\n","    vs.append(v)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.7726542878796787"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["sum(vs) / len(vs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8139601526785336\n","0.7811485925268133\n","0.5573255596332153\n","0.6003016438284001\n","0.5647555790728713\n","0.6556305506020975\n","0.566081191422976\n","0.6371792033409033\n","0.5762329915271931\n","0.6856117295584854\n","0.5730182858493165\n","0.5241341497908795\n","0.6810715710231423\n","0.5601318917666865\n","0.6364420146482986\n","0.6467236900110532\n","0.7712998218651923\n","0.6372925192606478\n","0.7427105279537056\n","0.5359980740615898\n","0.5888354218334927\n","0.580618688323033\n","0.6152277034249123\n","0.6551127124029308\n","0.5613817817090974\n","0.7638182991207666\n","0.6244175132527785\n","0.9306731011113104\n","0.7468965247649422\n","0.573959616932656\n","0.610123576967487\n","0.8387593683683431\n","0.9107745997693707\n","0.6190183645922452\n","0.6229527495603868\n","0.5866161944609583\n","0.6052439302995714\n","0.5518233489538567\n","0.6073179506320581\n","0.7738039433825015\n","0.6924440787045067\n","0.6045846268209495\n","0.8281845215296953\n","0.631697383909923\n","0.6518757348188167\n","0.5302854433633674\n","0.6337385926095921\n","0.6416660540884437\n","0.6056187701344267\n","0.4887550337997603\n","0.6690685668125779\n","0.8799474495716741\n","0.6663470414460126\n","0.5710496744204021\n","0.6180823419863702\n","0.6263501523778967\n","0.6563198951501763\n","0.7220561466615242\n","0.6218071978667871\n","0.7917183943889906\n","0.5722788890302917\n","0.6438429413010495\n","0.8288547030414852\n","0.698187717804562\n","0.6349792345993951\n","0.7636962427474178\n","0.5808546673813059\n","0.6757738189935834\n","0.7071607326595399\n","0.5836957355158411\n","0.7087420657007614\n","0.6307409626387493\n","0.741637936599284\n","0.8437345832919141\n","0.7702785961619651\n","0.5594629542407954\n","0.6322471838902248\n","0.5979004849186139\n","0.663363787669261\n","0.9482126656110292\n","0.5083926743085382\n","0.4818948151292748\n","0.8202215885152787\n","0.5826408542354294\n","0.7991781416806539\n","0.7022059752198068\n","0.7482544139103864\n","0.7378743474678235\n","0.6213556580077291\n","0.5604748197165154\n","0.3775653135247252\n","0.5143077296162266\n","0.45264628003729934\n","0.7048452026011046\n","0.6978756351599632\n","0.7411710908088357\n","0.545843470719011\n","0.7852442341880153\n","0.5595971909595168\n","0.6024192845000573\n","0.8583560680809533\n","0.6557803241974937\n"]}],"source":["vs = []\n","for a, b, c in zip(models['small_seed_0_epochs_10'], models['small_seed_1_epochs_10'], models['large_seed_0_epochs_10_mapped']):\n","    print(\n","        v := ((np.abs(c[0].cpu().numpy()) ** 2).sum() ** 0.5) / ((\n","            ((np.abs(a[0].cpu().numpy()) ** 2).sum() ** 0.5) +\n","            ((np.abs(b[0].cpu().numpy()) ** 2).sum() ** 0.5)\n","        ) / 2)\n","    )\n","    vs.append(v)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.6577432671287089"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["sum(vs) / len(vs)"]},{"cell_type":"markdown","metadata":{},"source":["## Inference & Evaluation\n","\n","With a trained model loaded into memory, we can now apply the model to batch_51. The following cells will start inference (or load in a csv with predictions, if you're in a hurry) and plot the results. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-03T08:46:55.299249Z","iopub.status.busy":"2023-02-03T08:46:55.298831Z","iopub.status.idle":"2023-02-03T08:46:55.307103Z","shell.execute_reply":"2023-02-03T08:46:55.306088Z","shell.execute_reply.started":"2023-02-03T08:46:55.299205Z"},"trusted":true},"outputs":[],"source":["def convert_to_3d(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Converts zenith and azimuth to 3D direction vectors\"\"\"\n","    df['true_x'] = np.cos(df['azimuth']) * np.sin(df['zenith'])\n","    df['true_y'] = np.sin(df['azimuth']) * np.sin(df['zenith'])\n","    df['true_z'] = np.cos(df['zenith'])\n","    return df\n","\n","def calculate_angular_error(df : pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Calcualtes the opening angle (angular error) between true and reconstructed direction vectors\"\"\"\n","    df['angular_error'] = np.arccos(df['true_x']*df['direction_x'] + df['true_y']*df['direction_y'] + df['true_z']*df['direction_z'])\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Predicting DataLoader 0: 100%|| 2000/2000 [02:14<00:00, 14.82it/s]\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 16:59:43 - inference - Writing results to training/train_model_without_configs/batch_1/dynedge_direction_my_example\u001b[0m\n"]}],"source":["# %%capture --no-stdout\n","# df = calculate_angular_error(convert_to_3d(inference(model_small_seed_0, config_small))) \n","# df.to_hdf('results/small_0.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Predicting DataLoader 0: 100%|| 2000/2000 [02:14<00:00, 14.82it/s]\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 17:02:31 - inference - Writing results to training/train_model_without_configs/batch_1/dynedge_direction_my_example\u001b[0m\n"]}],"source":["# %%capture --no-stdout\n","# df = calculate_angular_error(convert_to_3d(inference(model_small_seed_1, config_small))) \n","# df.to_hdf('results/small_1.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Predicting DataLoader 0: 100%|| 2000/2000 [03:48<00:00,  8.75it/s]\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:18:56 - inference - Writing results to training/train_model_without_configs/batch_1/dynedge_direction_my_example\u001b[0m\n"]}],"source":["# %%capture --no-stdout\n","# df = calculate_angular_error(convert_to_3d(inference(model_large, config_large)))\n","# df.to_hdf('results/large.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %%capture --no-stdout\n","# df = calculate_angular_error(convert_to_3d(inference(model_large_random, config_large_random)))\n","# df.to_hdf('results/large_random.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Predicting DataLoader 0: 100%|| 2000/2000 [03:48<00:00,  8.77it/s]\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 18:23:27 - inference - Writing results to training/train_model_without_configs/batch_1/dynedge_direction_my_example\u001b[0m\n"]}],"source":["# %%capture --no-stdout\n","# df = calculate_angular_error(convert_to_3d(inference(model_large_mapped, config_large)))\n","# df.to_hdf('results/large_mapped.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Predicting DataLoader 0: 100%|| 2000/2000 [02:15<00:00, 14.79it/s]\n","\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 17:05:19 - inference - Writing results to training/train_model_without_configs/batch_1/dynedge_direction_my_example\u001b[0m\n"]}],"source":["# %%capture --no-stdout\n","# df = calculate_angular_error(convert_to_3d(inference(model_small_mapped, config_small)))\n","# df.to_hdf('results/small_mapped.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%capture --no-stdout\n","df = calculate_angular_error(convert_to_3d(inference(models['large_seed_0_epochs_1_mapped'], config_large)))\n","df.to_hdf('results/large_seed_0_epochs_1_mapped.h5', key='df', mode='w')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = {\n","    'small_0': pd.read_hdf('results/small_0.h5', key='df'),\n","    'small_1': pd.read_hdf('results/small_1.h5', key='df'),\n","    'large': pd.read_hdf('results/large.h5', key='df'),\n","    'small_mapped': pd.read_hdf('results/small_mapped.h5', key='df'),\n","    'large_mapped': pd.read_hdf('results/large_mapped.h5', key='df'),\n","    'large_seed_0_epochs_1_mapped': pd.read_hdf('results/large_seed_0_epochs_1_mapped.h5', key='df'),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-03T08:56:19.735528Z","iopub.status.busy":"2023-02-03T08:56:19.735174Z","iopub.status.idle":"2023-02-03T08:56:19.981355Z","shell.execute_reply":"2023-02-03T08:56:19.980402Z","shell.execute_reply.started":"2023-02-03T08:56:19.735497Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7f9b08298940>"]},"execution_count":57,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 600x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig = plt.figure(figsize = (6,6))\n","for name, result in results.items():\n","    plt.hist(result['angular_error'], \n","            bins = np.arange(0,np.pi*2, 0.05), \n","            histtype = 'step', \n","            label = f'{name} mean AE: {np.round(result[\"angular_error\"].mean(),2)}')\n","    plt.xlabel('Angular Error [rad.]', size = 15)\n","    plt.ylabel('Counts', size = 15)\n","plt.title(f'{name}, Angular Error Distribution (Batch 51)', size = 15)\n","plt.legend(frameon = False, fontsize = 15)"]},{"cell_type":"markdown","metadata":{},"source":["So the pre-trained dynedge seems to perform quite well. Another interesting feature of the reconstruction is that dynedge (when coupled with the[ DirectionReconstructionWithKappa](https://github.com/graphnet-team/graphnet/blob/7e857562898ebebebc9a105159fd3d4eb4994aea/src/graphnet/models/task/reconstruction.py#L45) is that dynedge estimated *kappa* the concentration parameter from the vonMisesFisher distribution. Kappa is analogus to sigma via sigma = 1/sqrt(kappa), and the quality of the direction estimate should be highly correlated with this parameter. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-03T08:56:24.976250Z","iopub.status.busy":"2023-02-03T08:56:24.975565Z","iopub.status.idle":"2023-02-03T08:56:25.236386Z","shell.execute_reply":"2023-02-03T08:56:25.235418Z","shell.execute_reply.started":"2023-02-03T08:56:24.976211Z"},"trusted":true},"outputs":[],"source":["cut_threshold = 0.5\n","for name, result in results.items():\n","    fig = plt.figure(figsize = (6,6))\n","    plt.hist(result['angular_error'][1/np.sqrt(result['direction_kappa']) <= cut_threshold], \n","            bins = np.arange(0,np.pi*2, 0.05), \n","            histtype = 'step', \n","            label = f'sigma <= {cut_threshold}: {np.round(result[\"angular_error\"][1/np.sqrt(result[\"direction_kappa\"]) <= cut_threshold].mean(),2)}')\n","\n","    plt.hist(result['angular_error'][1/np.sqrt(result['direction_kappa']) > cut_threshold], \n","            bins = np.arange(0,np.pi*2, 0.05), \n","            histtype = 'step', \n","            label = f'sigma > {cut_threshold}: {np.round(result[\"angular_error\"][1/np.sqrt(result[\"direction_kappa\"]) > cut_threshold].mean(),2)}')\n","    plt.xlabel('Angular Error [rad.]', size = 15)\n","    plt.ylabel('Counts', size = 15)\n","    plt.title(f'{name}, Angular Error Distribution (Batch 51)', size = 15)\n","    plt.legend(frameon = False, fontsize = 15)"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, the variable can be used to distinguish \"good\" and \"bad\" reconstructions with some confidence. "]},{"cell_type":"markdown","metadata":{},"source":["## A few hints for your neutrino data science journey!\n","\n","* The configuration of dynedge shown in this notebook is the so-called \"baseline\". It's not optimized for high energy neutrinos, so you might be able to squeeze out a bit more performance by tuning hyperparameters or making larger modifications; such as switching out the learning rate scheduler or choosing a different loss function, etc.\n","\n","* You can use the kappa variable to group events into different categories. Perhaps training a seperate reconstruction method for each performs better?\n","\n","* You may want to adjust the [ParquetDataset](https://github.com/graphnet-team/graphnet/blob/7e857562898ebebebc9a105159fd3d4eb4994aea/src/graphnet/data/parquet/parquet_dataset.py#L11) such that it works with the competition data. This would allow you to train / infer directly on the competition files (No conversion to sqlite needed). Feel free to contribute this to the repository!\n","\n","\n","Good luck!"]}],"metadata":{"kernelspec":{"display_name":"graphnet","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"8bdc725fb65c21f82e45edbbae76c938f412b1b7259c22cf88bbbf1e62e294f2"}}},"nbformat":4,"nbformat_minor":4}
